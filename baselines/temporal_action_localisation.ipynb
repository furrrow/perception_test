{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMzYQoaXscbcQnYZ4/cxSSf",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/deepmind/perception_test/blob/main/baselines/temporal_action_localisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make sure GPU runtime is enabled!!"
      ],
      "metadata": {
        "id": "cEZwbpXoweWs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q_ljvdSjvfOR",
        "outputId": "e74e181b-2051-42ea-88b8-cd69962d213b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'actionformer_release_PT'...\n",
            "remote: Enumerating objects: 398, done.\u001b[K\n",
            "remote: Counting objects: 100% (25/25), done.\u001b[K\n",
            "remote: Compressing objects: 100% (25/25), done.\u001b[K\n",
            "remote: Total 398 (delta 9), reused 0 (delta 0), pack-reused 373\u001b[K\n",
            "Receiving objects: 100% (398/398), 639.31 KiB | 11.02 MiB/s, done.\n",
            "Resolving deltas: 100% (218/218), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/ptchallenge-workshop/actionformer_release_PT.git"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/actionformer_release_PT/libs/utils\n",
        "!python setup.py install --user\n",
        "%cd ../.."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PkjhKrz1wKeB",
        "outputId": "5f23c625-d057-42f0-f580-5fc766077cdd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/actionformer_release_PT/libs/utils\n",
            "running install\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: SetuptoolsDeprecationWarning: setup.py install is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` directly.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://blog.ganssle.io/articles/2021/10/setup-py-deprecated.html for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "/usr/local/lib/python3.10/dist-packages/setuptools/_distutils/cmd.py:66: EasyInstallDeprecationWarning: easy_install command is deprecated.\n",
            "!!\n",
            "\n",
            "        ********************************************************************************\n",
            "        Please avoid running ``setup.py`` and ``easy_install``.\n",
            "        Instead, use pypa/build, pypa/installer, pypa/build or\n",
            "        other standards-based tools.\n",
            "\n",
            "        See https://github.com/pypa/setuptools/issues/917 for details.\n",
            "        ********************************************************************************\n",
            "\n",
            "!!\n",
            "  self.initialize_options()\n",
            "running bdist_egg\n",
            "running egg_info\n",
            "creating nms_1d_cpu.egg-info\n",
            "writing nms_1d_cpu.egg-info/PKG-INFO\n",
            "writing dependency_links to nms_1d_cpu.egg-info/dependency_links.txt\n",
            "writing top-level names to nms_1d_cpu.egg-info/top_level.txt\n",
            "writing manifest file 'nms_1d_cpu.egg-info/SOURCES.txt'\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/cpp_extension.py:476: UserWarning: Attempted to use ninja as the BuildExtension backend but we could not find ninja.. Falling back to using the slow distutils backend.\n",
            "  warnings.warn(msg.format('we could not find ninja.'))\n",
            "reading manifest file 'nms_1d_cpu.egg-info/SOURCES.txt'\n",
            "writing manifest file 'nms_1d_cpu.egg-info/SOURCES.txt'\n",
            "installing library code to build/bdist.linux-x86_64/egg\n",
            "running install_lib\n",
            "running build_ext\n",
            "building 'nms_1d_cpu' extension\n",
            "creating build\n",
            "creating build/temp.linux-x86_64-cpython-310\n",
            "creating build/temp.linux-x86_64-cpython-310/csrc\n",
            "x86_64-linux-gnu-gcc -pthread -Wno-unused-result -Wsign-compare -DNDEBUG -g -fwrapv -O2 -Wall -g -fstack-protector-strong -Wformat -Werror=format-security -g -fwrapv -O2 -fPIC -I/usr/local/lib/python3.10/dist-packages/torch/include -I/usr/local/lib/python3.10/dist-packages/torch/include/torch/csrc/api/include -I/usr/local/lib/python3.10/dist-packages/torch/include/TH -I/usr/local/lib/python3.10/dist-packages/torch/include/THC -I/usr/include/python3.10 -c ./csrc/nms_cpu.cpp -o build/temp.linux-x86_64-cpython-310/./csrc/nms_cpu.o -fopenmp -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -DTORCH_EXTENSION_NAME=nms_1d_cpu -D_GLIBCXX_USE_CXX11_ABI=0 -std=c++17\n",
            "creating build/lib.linux-x86_64-cpython-310\n",
            "x86_64-linux-gnu-g++ -pthread -shared -Wl,-O1 -Wl,-Bsymbolic-functions -Wl,-Bsymbolic-functions -g -fwrapv -O2 build/temp.linux-x86_64-cpython-310/./csrc/nms_cpu.o -L/usr/local/lib/python3.10/dist-packages/torch/lib -L/usr/lib/x86_64-linux-gnu -lc10 -ltorch -ltorch_cpu -ltorch_python -o build/lib.linux-x86_64-cpython-310/nms_1d_cpu.cpython-310-x86_64-linux-gnu.so\n",
            "creating build/bdist.linux-x86_64\n",
            "creating build/bdist.linux-x86_64/egg\n",
            "copying build/lib.linux-x86_64-cpython-310/nms_1d_cpu.cpython-310-x86_64-linux-gnu.so -> build/bdist.linux-x86_64/egg\n",
            "creating stub loader for nms_1d_cpu.cpython-310-x86_64-linux-gnu.so\n",
            "byte-compiling build/bdist.linux-x86_64/egg/nms_1d_cpu.py to nms_1d_cpu.cpython-310.pyc\n",
            "creating build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying nms_1d_cpu.egg-info/PKG-INFO -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying nms_1d_cpu.egg-info/SOURCES.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying nms_1d_cpu.egg-info/dependency_links.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "copying nms_1d_cpu.egg-info/top_level.txt -> build/bdist.linux-x86_64/egg/EGG-INFO\n",
            "writing build/bdist.linux-x86_64/egg/EGG-INFO/native_libs.txt\n",
            "zip_safe flag not set; analyzing archive contents...\n",
            "__pycache__.nms_1d_cpu.cpython-310: module references __file__\n",
            "creating dist\n",
            "creating 'dist/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg' and adding 'build/bdist.linux-x86_64/egg' to it\n",
            "removing 'build/bdist.linux-x86_64/egg' (and everything under it)\n",
            "Processing nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
            "creating /root/.local/lib/python3.10/site-packages/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
            "Extracting nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg to /root/.local/lib/python3.10/site-packages\n",
            "Adding nms-1d-cpu 0.0.0 to easy-install.pth file\n",
            "\n",
            "Installed /root/.local/lib/python3.10/site-packages/nms_1d_cpu-0.0.0-py3.10-linux-x86_64.egg\n",
            "Processing dependencies for nms-1d-cpu==0.0.0\n",
            "Finished processing dependencies for nms-1d-cpu==0.0.0\n",
            "/content/actionformer_release_PT\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import zipfile\n",
        "import requests\n",
        "\n",
        "\n",
        "def download_and_unzip(url: str, destination: str):\n",
        "  \"\"\"Downloads and unzips a .zip file to a destination.\n",
        "\n",
        "  Downloads a file from the specified URL, saves it to the destination\n",
        "  directory, and then extracts its contents.\n",
        "\n",
        "  If the file is larger than 1GB, it will be downloaded in chunks,\n",
        "  and the download progress will be displayed.\n",
        "\n",
        "  Args:\n",
        "    url (str): The URL of the file to download.\n",
        "    destination (str): The destination directory to save the file and\n",
        "      extract its contents.\n",
        "  \"\"\"\n",
        "  if not os.path.exists(destination):\n",
        "    os.makedirs(destination)\n",
        "\n",
        "  filename = url.split('/')[-1]\n",
        "  file_path = os.path.join(destination, filename)\n",
        "\n",
        "  if os.path.exists(file_path):\n",
        "    print(f'{filename} already exists. Skipping download.')\n",
        "    return\n",
        "\n",
        "  response = requests.get(url, stream=True)\n",
        "  total_size = int(response.headers.get('content-length', 0))\n",
        "  gb = 1024*1024*1024\n",
        "\n",
        "  if total_size / gb > 1:\n",
        "    print(f'{filename} is larger than 1GB, downloading in chunks')\n",
        "    chunk_flag = True\n",
        "    chunk_size = int(total_size/100)\n",
        "  else:\n",
        "    chunk_flag = False\n",
        "    chunk_size = total_size\n",
        "\n",
        "  with open(file_path, 'wb') as file:\n",
        "    for chunk_idx, chunk in enumerate(\n",
        "        response.iter_content(chunk_size=chunk_size)):\n",
        "      if chunk:\n",
        "        if chunk_flag:\n",
        "          print(f\"\"\"{chunk_idx}% downloading\n",
        "          {round((chunk_idx*chunk_size)/gb, 1)}GB\n",
        "          / {round(total_size/gb, 1)}GB\"\"\")\n",
        "        file.write(chunk)\n",
        "  print(f\"'{filename}' downloaded successfully.\")\n",
        "\n",
        "  with zipfile.ZipFile(file_path, 'r') as zip_ref:\n",
        "    zip_ref.extractall(destination)\n",
        "  print(f\"'{filename}' extracted successfully.\")\n",
        "\n",
        "  os.remove(file_path)"
      ],
      "metadata": {
        "id": "E0gEbwfQxDiJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir data\n",
        "!mkdir data/pt"
      ],
      "metadata": {
        "id": "EQPGBjbXzr4G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# @title Download data\n",
        "data_path = './data/pt'\n",
        "\n",
        "train_annot_url = 'https://storage.googleapis.com/dm-perception-test/zip_data/action_localisation_train_annotations.zip'\n",
        "download_and_unzip(train_annot_url, data_path)\n",
        "train_feat_url = 'https://storage.googleapis.com/dm-perception-test/zip_data/action_localisation_train_video_features.zip'\n",
        "download_and_unzip(train_feat_url, data_path)\n",
        "\n",
        "valid_annot_url = 'https://storage.googleapis.com/dm-perception-test/zip_data/action_localisation_valid_annotations.zip'\n",
        "download_and_unzip(valid_annot_url, data_path)\n",
        "valid_feat_url = 'https://storage.googleapis.com/dm-perception-test/zip_data/action_localisation_valid_video_features.zip'\n",
        "download_and_unzip(valid_feat_url, data_path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PoOy1uhUyusl",
        "outputId": "cd96587a-0bd7-48a6-8c2a-1ddf5f81d1a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "'action_localisation_train_annotations.zip' downloaded successfully.\n",
            "'action_localisation_train_annotations.zip' extracted successfully.\n",
            "'action_localisation_train_video_features.zip' downloaded successfully.\n",
            "'action_localisation_train_video_features.zip' extracted successfully.\n",
            "'action_localisation_valid_annotations.zip' downloaded successfully.\n",
            "'action_localisation_valid_annotations.zip' extracted successfully.\n",
            "'action_localisation_valid_video_features.zip' downloaded successfully.\n",
            "'action_localisation_valid_video_features.zip' extracted successfully.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python3 train.py configs/perception_video_train.yaml --output reproduce"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uR8pmMJjwx2Y",
        "outputId": "30d91661-5660-43b7-ee43-501d55f263ad"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2023-07-04 12:12:56.076110: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
            "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
            "2023-07-04 12:12:57.421898: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
            "{'dataset': {'crop_ratio': [0.9, 1.0],\n",
            "             'default_fps': 15,\n",
            "             'downsample_rate': 1,\n",
            "             'feat_folder': './data/pt/action_localisation_train_video_features',\n",
            "             'feat_stride': 16,\n",
            "             'file_ext': '.npy',\n",
            "             'file_prefix': 'v_',\n",
            "             'force_upsampling': True,\n",
            "             'input_dim': 512,\n",
            "             'input_modality': 'video',\n",
            "             'json_file': './data/pt/action_localisation_train.json',\n",
            "             'max_seq_len': 192,\n",
            "             'mm_feat_folder': None,\n",
            "             'num_classes': 63,\n",
            "             'num_frames': 16,\n",
            "             'trunc_thresh': 0.5},\n",
            " 'dataset_name': 'perception',\n",
            " 'devices': ['cuda:0'],\n",
            " 'init_rand_seed': 1234567891,\n",
            " 'loader': {'batch_size': 16, 'num_workers': 4},\n",
            " 'model': {'backbone_arch': (2, 2, 5),\n",
            "           'backbone_type': 'convTransformer',\n",
            "           'embd_dim': 512,\n",
            "           'embd_kernel_size': 3,\n",
            "           'embd_with_ln': True,\n",
            "           'fpn_dim': 512,\n",
            "           'fpn_start_level': 0,\n",
            "           'fpn_type': 'identity',\n",
            "           'fpn_with_ln': True,\n",
            "           'head_dim': 512,\n",
            "           'head_kernel_size': 3,\n",
            "           'head_num_layers': 3,\n",
            "           'head_with_ln': True,\n",
            "           'input_dim': 512,\n",
            "           'max_buffer_len_factor': 1.0,\n",
            "           'max_seq_len': 192,\n",
            "           'n_head': 8,\n",
            "           'n_mha_win_size': [7, 7, 7, 7, 7, -1],\n",
            "           'num_classes': 63,\n",
            "           'regression_range': [(0, 4),\n",
            "                                (4, 8),\n",
            "                                (8, 16),\n",
            "                                (16, 32),\n",
            "                                (32, 64),\n",
            "                                (64, 10000)],\n",
            "           'scale_factor': 2,\n",
            "           'test_cfg': {'duration_thresh': 0.05,\n",
            "                        'ext_score_file': None,\n",
            "                        'iou_threshold': 0.1,\n",
            "                        'max_seg_num': 2000,\n",
            "                        'min_score': 0.001,\n",
            "                        'multiclass_nms': True,\n",
            "                        'nms_method': 'soft',\n",
            "                        'nms_sigma': 0.4,\n",
            "                        'pre_nms_thresh': 0.001,\n",
            "                        'pre_nms_topk': 5000,\n",
            "                        'voting_thresh': 0.75},\n",
            "           'train_cfg': {'center_sample': 'radius',\n",
            "                         'center_sample_radius': 1.5,\n",
            "                         'clip_grad_l2norm': 1.0,\n",
            "                         'cls_prior_prob': 0.01,\n",
            "                         'dropout': 0.0,\n",
            "                         'droppath': 0.1,\n",
            "                         'head_empty_cls': [],\n",
            "                         'init_loss_norm': 250,\n",
            "                         'label_smoothing': 0.0,\n",
            "                         'loss_weight': 1.0},\n",
            "           'use_abs_pe': True,\n",
            "           'use_rel_pe': False},\n",
            " 'model_name': 'LocPointTransformer',\n",
            " 'opt': {'epochs': 30,\n",
            "         'learning_rate': 0.001,\n",
            "         'momentum': 0.9,\n",
            "         'schedule_gamma': 0.1,\n",
            "         'schedule_steps': [],\n",
            "         'schedule_type': 'cosine',\n",
            "         'type': 'AdamW',\n",
            "         'warmup': True,\n",
            "         'warmup_epochs': 5,\n",
            "         'weight_decay': 0.05},\n",
            " 'output_folder': './ckpt/',\n",
            " 'test_cfg': {'duration_thresh': 0.05,\n",
            "              'ext_score_file': None,\n",
            "              'iou_threshold': 0.1,\n",
            "              'max_seg_num': 2000,\n",
            "              'min_score': 0.001,\n",
            "              'multiclass_nms': True,\n",
            "              'nms_method': 'soft',\n",
            "              'nms_sigma': 0.4,\n",
            "              'pre_nms_thresh': 0.001,\n",
            "              'pre_nms_topk': 5000,\n",
            "              'voting_thresh': 0.75},\n",
            " 'train_cfg': {'center_sample': 'radius',\n",
            "               'center_sample_radius': 1.5,\n",
            "               'clip_grad_l2norm': 1.0,\n",
            "               'cls_prior_prob': 0.01,\n",
            "               'dropout': 0.0,\n",
            "               'droppath': 0.1,\n",
            "               'head_empty_cls': [],\n",
            "               'init_loss_norm': 250,\n",
            "               'label_smoothing': 0.0,\n",
            "               'loss_weight': 1.0},\n",
            " 'train_split': ['train'],\n",
            " 'val_split': ['valid']}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Using model EMA ...\n",
            "\n",
            "Start training model LocPointTransformer ...\n",
            "\n",
            "[Train]: Epoch 0 started\n",
            "Epoch: [000][00010/00133]\tTime 1.93 (1.93)\tLoss 1.39 (1.39)\n",
            "\t\tcls_loss 0.92 (0.92)\treg_loss 0.47 (0.47)\n",
            "Epoch: [000][00020/00133]\tTime 0.48 (1.21)\tLoss 1.20 (1.30)\n",
            "\t\tcls_loss 0.82 (0.87)\treg_loss 0.38 (0.42)\n",
            "Epoch: [000][00030/00133]\tTime 0.44 (0.95)\tLoss 1.12 (1.24)\n",
            "\t\tcls_loss 0.76 (0.84)\treg_loss 0.36 (0.40)\n",
            "Epoch: [000][00040/00133]\tTime 0.37 (0.81)\tLoss 1.01 (1.18)\n",
            "\t\tcls_loss 0.67 (0.80)\treg_loss 0.34 (0.38)\n",
            "Epoch: [000][00050/00133]\tTime 0.36 (0.72)\tLoss 1.20 (1.18)\n",
            "\t\tcls_loss 0.80 (0.80)\treg_loss 0.40 (0.39)\n",
            "Epoch: [000][00060/00133]\tTime 0.41 (0.67)\tLoss 0.85 (1.13)\n",
            "\t\tcls_loss 0.57 (0.76)\treg_loss 0.29 (0.37)\n",
            "Epoch: [000][00070/00133]\tTime 0.37 (0.62)\tLoss 1.04 (1.12)\n",
            "\t\tcls_loss 0.67 (0.75)\treg_loss 0.37 (0.37)\n",
            "Epoch: [000][00080/00133]\tTime 0.37 (0.59)\tLoss 0.97 (1.10)\n",
            "\t\tcls_loss 0.65 (0.73)\treg_loss 0.32 (0.36)\n",
            "Epoch: [000][00090/00133]\tTime 0.43 (0.58)\tLoss 1.17 (1.11)\n",
            "\t\tcls_loss 0.75 (0.74)\treg_loss 0.42 (0.37)\n",
            "Epoch: [000][00100/00133]\tTime 0.37 (0.55)\tLoss 1.10 (1.11)\n",
            "\t\tcls_loss 0.69 (0.73)\treg_loss 0.41 (0.37)\n",
            "Epoch: [000][00110/00133]\tTime 0.37 (0.54)\tLoss 1.10 (1.10)\n",
            "\t\tcls_loss 0.71 (0.73)\treg_loss 0.39 (0.38)\n",
            "Epoch: [000][00120/00133]\tTime 0.40 (0.53)\tLoss 1.03 (1.10)\n",
            "\t\tcls_loss 0.66 (0.72)\treg_loss 0.37 (0.38)\n",
            "Epoch: [000][00130/00133]\tTime 0.39 (0.52)\tLoss 0.91 (1.08)\n",
            "\t\tcls_loss 0.60 (0.71)\treg_loss 0.31 (0.37)\n",
            "[Train]: Epoch 0 finished with lr=0.00020030\n",
            "\n",
            "\n",
            "[Train]: Epoch 1 started\n",
            "Epoch: [001][00010/00133]\tTime 0.42 (0.42)\tLoss 0.81 (0.81)\n",
            "\t\tcls_loss 0.52 (0.52)\treg_loss 0.29 (0.29)\n",
            "Epoch: [001][00020/00133]\tTime 0.39 (0.40)\tLoss 0.85 (0.83)\n",
            "\t\tcls_loss 0.54 (0.53)\treg_loss 0.31 (0.30)\n",
            "Epoch: [001][00030/00133]\tTime 0.41 (0.41)\tLoss 1.05 (0.90)\n",
            "\t\tcls_loss 0.66 (0.57)\treg_loss 0.39 (0.33)\n",
            "Epoch: [001][00040/00133]\tTime 0.36 (0.40)\tLoss 1.02 (0.93)\n",
            "\t\tcls_loss 0.65 (0.59)\treg_loss 0.37 (0.34)\n",
            "Epoch: [001][00050/00133]\tTime 0.37 (0.39)\tLoss 1.06 (0.96)\n",
            "\t\tcls_loss 0.67 (0.61)\treg_loss 0.39 (0.35)\n",
            "Epoch: [001][00060/00133]\tTime 0.42 (0.40)\tLoss 0.75 (0.92)\n",
            "\t\tcls_loss 0.47 (0.58)\treg_loss 0.28 (0.34)\n",
            "Epoch: [001][00070/00133]\tTime 0.36 (0.39)\tLoss 1.06 (0.94)\n",
            "\t\tcls_loss 0.67 (0.60)\treg_loss 0.39 (0.35)\n",
            "Epoch: [001][00080/00133]\tTime 0.38 (0.39)\tLoss 0.94 (0.94)\n",
            "\t\tcls_loss 0.58 (0.59)\treg_loss 0.36 (0.35)\n",
            "Epoch: [001][00090/00133]\tTime 0.54 (0.41)\tLoss 1.02 (0.95)\n",
            "\t\tcls_loss 0.63 (0.60)\treg_loss 0.39 (0.35)\n",
            "Epoch: [001][00100/00133]\tTime 0.40 (0.41)\tLoss 1.07 (0.96)\n",
            "\t\tcls_loss 0.67 (0.61)\treg_loss 0.40 (0.36)\n",
            "Epoch: [001][00110/00133]\tTime 0.38 (0.40)\tLoss 0.72 (0.94)\n",
            "\t\tcls_loss 0.46 (0.59)\treg_loss 0.26 (0.35)\n",
            "Epoch: [001][00120/00133]\tTime 0.45 (0.41)\tLoss 0.85 (0.93)\n",
            "\t\tcls_loss 0.54 (0.59)\treg_loss 0.31 (0.34)\n",
            "Epoch: [001][00130/00133]\tTime 0.36 (0.40)\tLoss 0.86 (0.93)\n",
            "\t\tcls_loss 0.55 (0.59)\treg_loss 0.31 (0.34)\n",
            "[Train]: Epoch 1 finished with lr=0.00040060\n",
            "\n",
            "\n",
            "[Train]: Epoch 2 started\n",
            "Epoch: [002][00010/00133]\tTime 0.43 (0.43)\tLoss 0.82 (0.82)\n",
            "\t\tcls_loss 0.52 (0.52)\treg_loss 0.30 (0.30)\n",
            "Epoch: [002][00020/00133]\tTime 0.42 (0.43)\tLoss 0.88 (0.85)\n",
            "\t\tcls_loss 0.55 (0.53)\treg_loss 0.33 (0.31)\n",
            "Epoch: [002][00030/00133]\tTime 0.38 (0.41)\tLoss 0.79 (0.83)\n",
            "\t\tcls_loss 0.49 (0.52)\treg_loss 0.30 (0.31)\n",
            "Epoch: [002][00040/00133]\tTime 0.37 (0.40)\tLoss 0.86 (0.83)\n",
            "\t\tcls_loss 0.55 (0.53)\treg_loss 0.31 (0.31)\n",
            "Epoch: [002][00050/00133]\tTime 0.39 (0.40)\tLoss 0.87 (0.84)\n",
            "\t\tcls_loss 0.55 (0.53)\treg_loss 0.32 (0.31)\n",
            "Epoch: [002][00060/00133]\tTime 0.39 (0.40)\tLoss 0.86 (0.85)\n",
            "\t\tcls_loss 0.56 (0.54)\treg_loss 0.30 (0.31)\n",
            "Epoch: [002][00070/00133]\tTime 0.37 (0.39)\tLoss 0.92 (0.86)\n",
            "\t\tcls_loss 0.57 (0.54)\treg_loss 0.35 (0.32)\n",
            "Epoch: [002][00080/00133]\tTime 0.39 (0.39)\tLoss 0.81 (0.85)\n",
            "\t\tcls_loss 0.51 (0.54)\treg_loss 0.30 (0.31)\n",
            "Epoch: [002][00090/00133]\tTime 0.41 (0.40)\tLoss 1.07 (0.87)\n",
            "\t\tcls_loss 0.72 (0.56)\treg_loss 0.35 (0.32)\n",
            "Epoch: [002][00100/00133]\tTime 0.36 (0.39)\tLoss 0.99 (0.89)\n",
            "\t\tcls_loss 0.61 (0.56)\treg_loss 0.38 (0.32)\n",
            "Epoch: [002][00110/00133]\tTime 0.37 (0.39)\tLoss 1.07 (0.90)\n",
            "\t\tcls_loss 0.68 (0.57)\treg_loss 0.39 (0.33)\n",
            "Epoch: [002][00120/00133]\tTime 0.43 (0.39)\tLoss 0.79 (0.89)\n",
            "\t\tcls_loss 0.50 (0.57)\treg_loss 0.29 (0.33)\n",
            "Epoch: [002][00130/00133]\tTime 0.35 (0.39)\tLoss 0.83 (0.89)\n",
            "\t\tcls_loss 0.54 (0.56)\treg_loss 0.29 (0.32)\n",
            "[Train]: Epoch 2 finished with lr=0.00060090\n",
            "\n",
            "\n",
            "[Train]: Epoch 3 started\n",
            "Epoch: [003][00010/00133]\tTime 0.42 (0.42)\tLoss 0.85 (0.85)\n",
            "\t\tcls_loss 0.55 (0.55)\treg_loss 0.31 (0.31)\n",
            "Epoch: [003][00020/00133]\tTime 0.42 (0.42)\tLoss 0.88 (0.87)\n",
            "\t\tcls_loss 0.57 (0.56)\treg_loss 0.31 (0.31)\n",
            "Epoch: [003][00030/00133]\tTime 0.36 (0.40)\tLoss 0.80 (0.85)\n",
            "\t\tcls_loss 0.50 (0.54)\treg_loss 0.31 (0.31)\n",
            "Epoch: [003][00040/00133]\tTime 0.36 (0.39)\tLoss 0.70 (0.81)\n",
            "\t\tcls_loss 0.44 (0.51)\treg_loss 0.26 (0.30)\n",
            "Epoch: [003][00050/00133]\tTime 0.41 (0.39)\tLoss 1.00 (0.85)\n",
            "\t\tcls_loss 0.64 (0.54)\treg_loss 0.36 (0.31)\n",
            "Epoch: [003][00060/00133]\tTime 0.39 (0.39)\tLoss 0.95 (0.86)\n",
            "\t\tcls_loss 0.59 (0.55)\treg_loss 0.36 (0.32)\n",
            "Epoch: [003][00070/00133]\tTime 0.38 (0.39)\tLoss 0.83 (0.86)\n",
            "\t\tcls_loss 0.50 (0.54)\treg_loss 0.33 (0.32)\n",
            "Epoch: [003][00080/00133]\tTime 0.37 (0.39)\tLoss 0.85 (0.86)\n",
            "\t\tcls_loss 0.53 (0.54)\treg_loss 0.31 (0.32)\n",
            "Epoch: [003][00090/00133]\tTime 0.41 (0.39)\tLoss 0.84 (0.86)\n",
            "\t\tcls_loss 0.50 (0.54)\treg_loss 0.34 (0.32)\n",
            "Epoch: [003][00100/00133]\tTime 0.38 (0.39)\tLoss 0.98 (0.87)\n",
            "\t\tcls_loss 0.64 (0.55)\treg_loss 0.34 (0.32)\n",
            "Epoch: [003][00110/00133]\tTime 0.39 (0.39)\tLoss 0.80 (0.86)\n",
            "\t\tcls_loss 0.50 (0.54)\treg_loss 0.31 (0.32)\n",
            "Epoch: [003][00120/00133]\tTime 0.43 (0.39)\tLoss 0.97 (0.87)\n",
            "\t\tcls_loss 0.61 (0.55)\treg_loss 0.36 (0.32)\n",
            "Epoch: [003][00130/00133]\tTime 0.36 (0.39)\tLoss 0.77 (0.86)\n",
            "\t\tcls_loss 0.51 (0.54)\treg_loss 0.26 (0.32)\n",
            "[Train]: Epoch 3 finished with lr=0.00080120\n",
            "\n",
            "\n",
            "[Train]: Epoch 4 started\n",
            "Epoch: [004][00010/00133]\tTime 0.44 (0.44)\tLoss 0.85 (0.85)\n",
            "\t\tcls_loss 0.55 (0.55)\treg_loss 0.30 (0.30)\n",
            "Epoch: [004][00020/00133]\tTime 0.42 (0.43)\tLoss 0.88 (0.86)\n",
            "\t\tcls_loss 0.57 (0.56)\treg_loss 0.31 (0.31)\n",
            "Epoch: [004][00030/00133]\tTime 0.38 (0.41)\tLoss 0.82 (0.85)\n",
            "\t\tcls_loss 0.50 (0.54)\treg_loss 0.32 (0.31)\n",
            "Epoch: [004][00040/00133]\tTime 0.37 (0.40)\tLoss 0.65 (0.80)\n",
            "\t\tcls_loss 0.42 (0.51)\treg_loss 0.24 (0.29)\n",
            "Epoch: [004][00050/00133]\tTime 0.44 (0.41)\tLoss 1.01 (0.84)\n",
            "\t\tcls_loss 0.65 (0.54)\treg_loss 0.36 (0.30)\n",
            "Epoch: [004][00060/00133]\tTime 0.37 (0.40)\tLoss 0.79 (0.83)\n",
            "\t\tcls_loss 0.51 (0.53)\treg_loss 0.28 (0.30)\n",
            "Epoch: [004][00070/00133]\tTime 0.36 (0.40)\tLoss 0.88 (0.84)\n",
            "\t\tcls_loss 0.57 (0.54)\treg_loss 0.32 (0.30)\n",
            "Epoch: [004][00080/00133]\tTime 0.41 (0.40)\tLoss 0.84 (0.84)\n",
            "\t\tcls_loss 0.53 (0.54)\treg_loss 0.31 (0.30)\n",
            "Epoch: [004][00090/00133]\tTime 0.40 (0.40)\tLoss 0.81 (0.84)\n",
            "\t\tcls_loss 0.52 (0.53)\treg_loss 0.29 (0.30)\n",
            "Epoch: [004][00100/00133]\tTime 0.37 (0.39)\tLoss 0.97 (0.85)\n",
            "\t\tcls_loss 0.62 (0.54)\treg_loss 0.35 (0.31)\n",
            "Epoch: [004][00110/00133]\tTime 0.40 (0.40)\tLoss 0.81 (0.85)\n",
            "\t\tcls_loss 0.54 (0.54)\treg_loss 0.26 (0.30)\n",
            "Epoch: [004][00120/00133]\tTime 0.42 (0.40)\tLoss 1.14 (0.87)\n",
            "\t\tcls_loss 0.72 (0.56)\treg_loss 0.42 (0.31)\n",
            "Epoch: [004][00130/00133]\tTime 0.39 (0.40)\tLoss 0.94 (0.88)\n",
            "\t\tcls_loss 0.57 (0.56)\treg_loss 0.36 (0.32)\n",
            "[Train]: Epoch 4 finished with lr=0.00100000\n",
            "\n",
            "\n",
            "[Train]: Epoch 5 started\n",
            "Epoch: [005][00010/00133]\tTime 0.47 (0.47)\tLoss 0.65 (0.65)\n",
            "\t\tcls_loss 0.43 (0.43)\treg_loss 0.23 (0.23)\n",
            "Epoch: [005][00020/00133]\tTime 0.38 (0.43)\tLoss 0.94 (0.80)\n",
            "\t\tcls_loss 0.60 (0.51)\treg_loss 0.34 (0.28)\n",
            "Epoch: [005][00030/00133]\tTime 0.37 (0.41)\tLoss 0.65 (0.75)\n",
            "\t\tcls_loss 0.42 (0.48)\treg_loss 0.24 (0.27)\n",
            "Epoch: [005][00040/00133]\tTime 0.39 (0.40)\tLoss 0.95 (0.80)\n",
            "\t\tcls_loss 0.61 (0.51)\treg_loss 0.34 (0.29)\n",
            "Epoch: [005][00050/00133]\tTime 0.43 (0.41)\tLoss 0.67 (0.77)\n",
            "\t\tcls_loss 0.40 (0.49)\treg_loss 0.27 (0.28)\n",
            "Epoch: [005][00060/00133]\tTime 0.37 (0.40)\tLoss 0.75 (0.77)\n",
            "\t\tcls_loss 0.46 (0.49)\treg_loss 0.29 (0.28)\n",
            "Epoch: [005][00070/00133]\tTime 0.37 (0.40)\tLoss 0.76 (0.77)\n",
            "\t\tcls_loss 0.48 (0.48)\treg_loss 0.28 (0.28)\n",
            "Epoch: [005][00080/00133]\tTime 0.42 (0.40)\tLoss 0.88 (0.78)\n",
            "\t\tcls_loss 0.54 (0.49)\treg_loss 0.34 (0.29)\n",
            "Epoch: [005][00090/00133]\tTime 0.38 (0.40)\tLoss 0.99 (0.81)\n",
            "\t\tcls_loss 0.63 (0.51)\treg_loss 0.36 (0.30)\n",
            "Epoch: [005][00100/00133]\tTime 0.37 (0.40)\tLoss 0.68 (0.79)\n",
            "\t\tcls_loss 0.43 (0.50)\treg_loss 0.25 (0.29)\n",
            "Epoch: [005][00110/00133]\tTime 0.42 (0.40)\tLoss 0.86 (0.80)\n",
            "\t\tcls_loss 0.53 (0.50)\treg_loss 0.33 (0.30)\n",
            "Epoch: [005][00120/00133]\tTime 0.38 (0.40)\tLoss 0.83 (0.80)\n",
            "\t\tcls_loss 0.54 (0.51)\treg_loss 0.29 (0.30)\n",
            "Epoch: [005][00130/00133]\tTime 0.37 (0.39)\tLoss 0.83 (0.80)\n",
            "\t\tcls_loss 0.52 (0.51)\treg_loss 0.32 (0.30)\n",
            "[Train]: Epoch 5 finished with lr=0.00099726\n",
            "\n",
            "\n",
            "[Train]: Epoch 6 started\n",
            "Epoch: [006][00010/00133]\tTime 0.49 (0.49)\tLoss 0.79 (0.79)\n",
            "\t\tcls_loss 0.50 (0.50)\treg_loss 0.29 (0.29)\n",
            "Epoch: [006][00020/00133]\tTime 0.37 (0.43)\tLoss 0.78 (0.78)\n",
            "\t\tcls_loss 0.48 (0.49)\treg_loss 0.30 (0.29)\n",
            "Epoch: [006][00030/00133]\tTime 0.40 (0.42)\tLoss 0.90 (0.82)\n",
            "\t\tcls_loss 0.58 (0.52)\treg_loss 0.31 (0.30)\n",
            "Epoch: [006][00040/00133]\tTime 0.45 (0.43)\tLoss 0.87 (0.83)\n",
            "\t\tcls_loss 0.54 (0.53)\treg_loss 0.33 (0.31)\n",
            "Epoch: [006][00050/00133]\tTime 0.39 (0.42)\tLoss 0.73 (0.81)\n",
            "\t\tcls_loss 0.47 (0.51)\treg_loss 0.27 (0.30)\n",
            "Epoch: [006][00060/00133]\tTime 0.38 (0.41)\tLoss 1.03 (0.85)\n",
            "\t\tcls_loss 0.66 (0.54)\treg_loss 0.38 (0.31)\n",
            "Epoch: [006][00070/00133]\tTime 0.41 (0.41)\tLoss 0.75 (0.84)\n",
            "\t\tcls_loss 0.49 (0.53)\treg_loss 0.26 (0.31)\n",
            "Epoch: [006][00080/00133]\tTime 0.41 (0.41)\tLoss 0.65 (0.81)\n",
            "\t\tcls_loss 0.41 (0.51)\treg_loss 0.24 (0.30)\n",
            "Epoch: [006][00090/00133]\tTime 0.40 (0.41)\tLoss 0.97 (0.83)\n",
            "\t\tcls_loss 0.65 (0.53)\treg_loss 0.32 (0.30)\n",
            "Epoch: [006][00100/00133]\tTime 0.39 (0.41)\tLoss 0.74 (0.82)\n",
            "\t\tcls_loss 0.45 (0.52)\treg_loss 0.29 (0.30)\n",
            "Epoch: [006][00110/00133]\tTime 0.43 (0.41)\tLoss 0.61 (0.80)\n",
            "\t\tcls_loss 0.39 (0.51)\treg_loss 0.21 (0.29)\n",
            "Epoch: [006][00120/00133]\tTime 0.38 (0.41)\tLoss 0.75 (0.80)\n",
            "\t\tcls_loss 0.48 (0.51)\treg_loss 0.28 (0.29)\n",
            "Epoch: [006][00130/00133]\tTime 0.37 (0.40)\tLoss 0.73 (0.79)\n",
            "\t\tcls_loss 0.45 (0.50)\treg_loss 0.28 (0.29)\n",
            "[Train]: Epoch 6 finished with lr=0.00098907\n",
            "\n",
            "\n",
            "[Train]: Epoch 7 started\n",
            "Epoch: [007][00010/00133]\tTime 0.49 (0.49)\tLoss 0.70 (0.70)\n",
            "\t\tcls_loss 0.46 (0.46)\treg_loss 0.25 (0.25)\n",
            "Epoch: [007][00020/00133]\tTime 0.37 (0.43)\tLoss 0.71 (0.71)\n",
            "\t\tcls_loss 0.44 (0.45)\treg_loss 0.27 (0.26)\n",
            "Epoch: [007][00030/00133]\tTime 0.37 (0.41)\tLoss 0.95 (0.79)\n",
            "\t\tcls_loss 0.60 (0.50)\treg_loss 0.35 (0.29)\n",
            "Epoch: [007][00040/00133]\tTime 0.44 (0.42)\tLoss 1.02 (0.85)\n",
            "\t\tcls_loss 0.62 (0.53)\treg_loss 0.40 (0.32)\n",
            "Epoch: [007][00050/00133]\tTime 0.39 (0.41)\tLoss 0.88 (0.85)\n",
            "\t\tcls_loss 0.57 (0.54)\treg_loss 0.31 (0.31)\n",
            "Epoch: [007][00060/00133]\tTime 0.37 (0.40)\tLoss 0.81 (0.85)\n",
            "\t\tcls_loss 0.51 (0.53)\treg_loss 0.29 (0.31)\n",
            "Epoch: [007][00070/00133]\tTime 0.44 (0.41)\tLoss 0.75 (0.83)\n",
            "\t\tcls_loss 0.47 (0.52)\treg_loss 0.28 (0.31)\n",
            "Epoch: [007][00080/00133]\tTime 0.37 (0.40)\tLoss 0.67 (0.81)\n",
            "\t\tcls_loss 0.42 (0.51)\treg_loss 0.26 (0.30)\n",
            "Epoch: [007][00090/00133]\tTime 0.38 (0.40)\tLoss 0.94 (0.83)\n",
            "\t\tcls_loss 0.60 (0.52)\treg_loss 0.34 (0.30)\n",
            "Epoch: [007][00100/00133]\tTime 0.42 (0.40)\tLoss 0.98 (0.84)\n",
            "\t\tcls_loss 0.61 (0.53)\treg_loss 0.37 (0.31)\n",
            "Epoch: [007][00110/00133]\tTime 0.39 (0.40)\tLoss 0.74 (0.83)\n",
            "\t\tcls_loss 0.45 (0.52)\treg_loss 0.29 (0.31)\n",
            "Epoch: [007][00120/00133]\tTime 0.37 (0.40)\tLoss 0.84 (0.83)\n",
            "\t\tcls_loss 0.49 (0.52)\treg_loss 0.35 (0.31)\n",
            "Epoch: [007][00130/00133]\tTime 0.37 (0.40)\tLoss 0.95 (0.84)\n",
            "\t\tcls_loss 0.59 (0.53)\treg_loss 0.36 (0.32)\n",
            "[Train]: Epoch 7 finished with lr=0.00097553\n",
            "\n",
            "\n",
            "[Train]: Epoch 8 started\n",
            "Epoch: [008][00010/00133]\tTime 0.48 (0.48)\tLoss 0.97 (0.97)\n",
            "\t\tcls_loss 0.62 (0.62)\treg_loss 0.34 (0.34)\n",
            "Epoch: [008][00020/00133]\tTime 0.38 (0.43)\tLoss 0.72 (0.84)\n",
            "\t\tcls_loss 0.46 (0.54)\treg_loss 0.26 (0.30)\n",
            "Epoch: [008][00030/00133]\tTime 0.39 (0.42)\tLoss 0.81 (0.83)\n",
            "\t\tcls_loss 0.51 (0.53)\treg_loss 0.30 (0.30)\n",
            "Epoch: [008][00040/00133]\tTime 0.41 (0.42)\tLoss 0.78 (0.82)\n",
            "\t\tcls_loss 0.52 (0.53)\treg_loss 0.26 (0.29)\n",
            "Epoch: [008][00050/00133]\tTime 0.39 (0.41)\tLoss 0.87 (0.83)\n",
            "\t\tcls_loss 0.55 (0.53)\treg_loss 0.32 (0.30)\n",
            "Epoch: [008][00060/00133]\tTime 0.37 (0.40)\tLoss 0.93 (0.85)\n",
            "\t\tcls_loss 0.56 (0.54)\treg_loss 0.38 (0.31)\n",
            "Epoch: [008][00070/00133]\tTime 0.42 (0.41)\tLoss 0.76 (0.83)\n",
            "\t\tcls_loss 0.48 (0.53)\treg_loss 0.28 (0.30)\n",
            "Epoch: [008][00080/00133]\tTime 0.38 (0.40)\tLoss 0.83 (0.83)\n",
            "\t\tcls_loss 0.52 (0.53)\treg_loss 0.31 (0.31)\n",
            "Epoch: [008][00090/00133]\tTime 0.38 (0.40)\tLoss 0.71 (0.82)\n",
            "\t\tcls_loss 0.43 (0.52)\treg_loss 0.27 (0.30)\n",
            "Epoch: [008][00100/00133]\tTime 0.42 (0.40)\tLoss 0.87 (0.82)\n",
            "\t\tcls_loss 0.56 (0.52)\treg_loss 0.31 (0.30)\n",
            "Epoch: [008][00110/00133]\tTime 0.38 (0.40)\tLoss 0.68 (0.81)\n",
            "\t\tcls_loss 0.43 (0.51)\treg_loss 0.25 (0.30)\n",
            "Epoch: [008][00120/00133]\tTime 0.38 (0.40)\tLoss 0.88 (0.82)\n",
            "\t\tcls_loss 0.54 (0.52)\treg_loss 0.34 (0.30)\n",
            "Epoch: [008][00130/00133]\tTime 0.38 (0.40)\tLoss 0.90 (0.82)\n",
            "\t\tcls_loss 0.55 (0.52)\treg_loss 0.35 (0.31)\n",
            "[Train]: Epoch 8 finished with lr=0.00095677\n",
            "\n",
            "\n",
            "[Train]: Epoch 9 started\n",
            "Epoch: [009][00010/00133]\tTime 0.43 (0.43)\tLoss 0.72 (0.72)\n",
            "\t\tcls_loss 0.45 (0.45)\treg_loss 0.27 (0.27)\n",
            "Epoch: [009][00020/00133]\tTime 0.39 (0.41)\tLoss 0.79 (0.75)\n",
            "\t\tcls_loss 0.49 (0.47)\treg_loss 0.29 (0.28)\n",
            "Epoch: [009][00030/00133]\tTime 0.42 (0.41)\tLoss 0.60 (0.70)\n",
            "\t\tcls_loss 0.37 (0.44)\treg_loss 0.23 (0.27)\n",
            "Epoch: [009][00040/00133]\tTime 0.38 (0.40)\tLoss 0.80 (0.73)\n",
            "\t\tcls_loss 0.50 (0.45)\treg_loss 0.30 (0.27)\n",
            "Epoch: [009][00050/00133]\tTime 0.37 (0.40)\tLoss 0.67 (0.72)\n",
            "\t\tcls_loss 0.43 (0.45)\treg_loss 0.24 (0.27)\n",
            "Epoch: [009][00060/00133]\tTime 0.39 (0.40)\tLoss 0.90 (0.75)\n",
            "\t\tcls_loss 0.57 (0.47)\treg_loss 0.33 (0.28)\n",
            "Epoch: [009][00070/00133]\tTime 0.41 (0.40)\tLoss 0.74 (0.75)\n",
            "\t\tcls_loss 0.50 (0.47)\treg_loss 0.24 (0.27)\n",
            "Epoch: [009][00080/00133]\tTime 0.37 (0.39)\tLoss 0.67 (0.74)\n",
            "\t\tcls_loss 0.43 (0.47)\treg_loss 0.24 (0.27)\n",
            "Epoch: [009][00090/00133]\tTime 0.39 (0.39)\tLoss 1.01 (0.77)\n",
            "\t\tcls_loss 0.62 (0.48)\treg_loss 0.39 (0.28)\n",
            "Epoch: [009][00100/00133]\tTime 0.43 (0.40)\tLoss 1.03 (0.79)\n",
            "\t\tcls_loss 0.62 (0.50)\treg_loss 0.41 (0.30)\n",
            "Epoch: [009][00110/00133]\tTime 0.36 (0.39)\tLoss 0.84 (0.80)\n",
            "\t\tcls_loss 0.51 (0.50)\treg_loss 0.33 (0.30)\n",
            "Epoch: [009][00120/00133]\tTime 0.37 (0.39)\tLoss 0.64 (0.78)\n",
            "\t\tcls_loss 0.41 (0.49)\treg_loss 0.23 (0.29)\n",
            "Epoch: [009][00130/00133]\tTime 0.44 (0.40)\tLoss 0.68 (0.78)\n",
            "\t\tcls_loss 0.42 (0.49)\treg_loss 0.26 (0.29)\n",
            "[Train]: Epoch 9 finished with lr=0.00093301\n",
            "\n",
            "\n",
            "[Train]: Epoch 10 started\n",
            "Epoch: [010][00010/00133]\tTime 0.46 (0.46)\tLoss 0.85 (0.85)\n",
            "\t\tcls_loss 0.55 (0.55)\treg_loss 0.30 (0.30)\n",
            "Epoch: [010][00020/00133]\tTime 0.38 (0.42)\tLoss 0.92 (0.89)\n",
            "\t\tcls_loss 0.55 (0.55)\treg_loss 0.37 (0.34)\n",
            "Epoch: [010][00030/00133]\tTime 0.37 (0.40)\tLoss 0.63 (0.80)\n",
            "\t\tcls_loss 0.43 (0.51)\treg_loss 0.19 (0.29)\n",
            "Epoch: [010][00040/00133]\tTime 0.40 (0.40)\tLoss 0.68 (0.77)\n",
            "\t\tcls_loss 0.40 (0.48)\treg_loss 0.28 (0.29)\n",
            "Epoch: [010][00050/00133]\tTime 0.42 (0.41)\tLoss 0.93 (0.80)\n",
            "\t\tcls_loss 0.56 (0.50)\treg_loss 0.37 (0.30)\n",
            "Epoch: [010][00060/00133]\tTime 0.37 (0.40)\tLoss 0.88 (0.82)\n",
            "\t\tcls_loss 0.54 (0.51)\treg_loss 0.35 (0.31)\n",
            "Epoch: [010][00070/00133]\tTime 0.37 (0.40)\tLoss 0.90 (0.83)\n",
            "\t\tcls_loss 0.53 (0.51)\treg_loss 0.37 (0.32)\n",
            "Epoch: [010][00080/00133]\tTime 0.44 (0.40)\tLoss 0.91 (0.84)\n",
            "\t\tcls_loss 0.58 (0.52)\treg_loss 0.33 (0.32)\n",
            "Epoch: [010][00090/00133]\tTime 0.37 (0.40)\tLoss 0.82 (0.84)\n",
            "\t\tcls_loss 0.52 (0.52)\treg_loss 0.29 (0.32)\n",
            "Epoch: [010][00100/00133]\tTime 0.39 (0.40)\tLoss 0.76 (0.83)\n",
            "\t\tcls_loss 0.50 (0.52)\treg_loss 0.26 (0.31)\n",
            "Epoch: [010][00110/00133]\tTime 0.43 (0.40)\tLoss 0.59 (0.81)\n",
            "\t\tcls_loss 0.37 (0.50)\treg_loss 0.22 (0.30)\n",
            "Epoch: [010][00120/00133]\tTime 0.36 (0.40)\tLoss 0.81 (0.81)\n",
            "\t\tcls_loss 0.53 (0.50)\treg_loss 0.28 (0.30)\n",
            "Epoch: [010][00130/00133]\tTime 0.37 (0.40)\tLoss 0.74 (0.80)\n",
            "\t\tcls_loss 0.46 (0.50)\treg_loss 0.28 (0.30)\n",
            "[Train]: Epoch 10 finished with lr=0.00090451\n",
            "\n",
            "\n",
            "[Train]: Epoch 11 started\n",
            "Epoch: [011][00010/00133]\tTime 0.48 (0.48)\tLoss 0.93 (0.93)\n",
            "\t\tcls_loss 0.59 (0.59)\treg_loss 0.33 (0.33)\n",
            "Epoch: [011][00020/00133]\tTime 0.38 (0.43)\tLoss 0.67 (0.80)\n",
            "\t\tcls_loss 0.42 (0.51)\treg_loss 0.25 (0.29)\n",
            "Epoch: [011][00030/00133]\tTime 0.39 (0.42)\tLoss 0.69 (0.76)\n",
            "\t\tcls_loss 0.42 (0.48)\treg_loss 0.27 (0.28)\n",
            "Epoch: [011][00040/00133]\tTime 0.42 (0.42)\tLoss 0.77 (0.76)\n",
            "\t\tcls_loss 0.45 (0.47)\treg_loss 0.32 (0.29)\n",
            "Epoch: [011][00050/00133]\tTime 0.38 (0.41)\tLoss 0.90 (0.79)\n",
            "\t\tcls_loss 0.58 (0.49)\treg_loss 0.32 (0.30)\n",
            "Epoch: [011][00060/00133]\tTime 0.39 (0.41)\tLoss 0.83 (0.80)\n",
            "\t\tcls_loss 0.52 (0.50)\treg_loss 0.31 (0.30)\n",
            "Epoch: [011][00070/00133]\tTime 0.39 (0.40)\tLoss 0.73 (0.79)\n",
            "\t\tcls_loss 0.46 (0.49)\treg_loss 0.27 (0.30)\n",
            "Epoch: [011][00080/00133]\tTime 0.44 (0.41)\tLoss 1.00 (0.81)\n",
            "\t\tcls_loss 0.64 (0.51)\treg_loss 0.36 (0.30)\n",
            "Epoch: [011][00090/00133]\tTime 0.38 (0.40)\tLoss 0.92 (0.83)\n",
            "\t\tcls_loss 0.59 (0.52)\treg_loss 0.33 (0.31)\n",
            "Epoch: [011][00100/00133]\tTime 0.39 (0.40)\tLoss 0.68 (0.81)\n",
            "\t\tcls_loss 0.42 (0.51)\treg_loss 0.26 (0.30)\n",
            "Epoch: [011][00110/00133]\tTime 0.44 (0.41)\tLoss 0.68 (0.80)\n",
            "\t\tcls_loss 0.42 (0.50)\treg_loss 0.26 (0.30)\n",
            "Epoch: [011][00120/00133]\tTime 0.38 (0.40)\tLoss 0.75 (0.79)\n",
            "\t\tcls_loss 0.46 (0.50)\treg_loss 0.29 (0.30)\n",
            "Epoch: [011][00130/00133]\tTime 0.36 (0.40)\tLoss 0.76 (0.79)\n",
            "\t\tcls_loss 0.48 (0.50)\treg_loss 0.28 (0.30)\n",
            "[Train]: Epoch 11 finished with lr=0.00087157\n",
            "\n",
            "\n",
            "[Train]: Epoch 12 started\n",
            "Epoch: [012][00010/00133]\tTime 0.48 (0.48)\tLoss 0.74 (0.74)\n",
            "\t\tcls_loss 0.45 (0.45)\treg_loss 0.29 (0.29)\n",
            "Epoch: [012][00020/00133]\tTime 0.37 (0.42)\tLoss 0.76 (0.75)\n",
            "\t\tcls_loss 0.47 (0.46)\treg_loss 0.29 (0.29)\n",
            "Epoch: [012][00030/00133]\tTime 0.37 (0.41)\tLoss 0.81 (0.77)\n",
            "\t\tcls_loss 0.50 (0.48)\treg_loss 0.30 (0.29)\n",
            "Epoch: [012][00040/00133]\tTime 0.43 (0.41)\tLoss 0.91 (0.80)\n",
            "\t\tcls_loss 0.56 (0.50)\treg_loss 0.35 (0.31)\n",
            "Epoch: [012][00050/00133]\tTime 0.40 (0.41)\tLoss 0.71 (0.79)\n",
            "\t\tcls_loss 0.46 (0.49)\treg_loss 0.25 (0.30)\n",
            "Epoch: [012][00060/00133]\tTime 0.38 (0.40)\tLoss 0.62 (0.76)\n",
            "\t\tcls_loss 0.40 (0.47)\treg_loss 0.22 (0.28)\n",
            "Epoch: [012][00070/00133]\tTime 0.42 (0.41)\tLoss 0.99 (0.79)\n",
            "\t\tcls_loss 0.62 (0.49)\treg_loss 0.37 (0.30)\n",
            "Epoch: [012][00080/00133]\tTime 0.39 (0.40)\tLoss 0.75 (0.79)\n",
            "\t\tcls_loss 0.46 (0.49)\treg_loss 0.28 (0.29)\n",
            "Epoch: [012][00090/00133]\tTime 0.36 (0.40)\tLoss 0.77 (0.78)\n",
            "\t\tcls_loss 0.44 (0.48)\treg_loss 0.33 (0.30)\n",
            "Epoch: [012][00100/00133]\tTime 0.42 (0.40)\tLoss 0.71 (0.78)\n",
            "\t\tcls_loss 0.45 (0.48)\treg_loss 0.26 (0.30)\n",
            "Epoch: [012][00110/00133]\tTime 0.42 (0.40)\tLoss 0.67 (0.77)\n",
            "\t\tcls_loss 0.41 (0.47)\treg_loss 0.26 (0.29)\n",
            "Epoch: [012][00120/00133]\tTime 0.38 (0.40)\tLoss 0.78 (0.77)\n",
            "\t\tcls_loss 0.48 (0.47)\treg_loss 0.30 (0.29)\n",
            "Epoch: [012][00130/00133]\tTime 0.37 (0.40)\tLoss 0.77 (0.77)\n",
            "\t\tcls_loss 0.47 (0.47)\treg_loss 0.30 (0.29)\n",
            "[Train]: Epoch 12 finished with lr=0.00083457\n",
            "\n",
            "\n",
            "[Train]: Epoch 13 started\n",
            "Epoch: [013][00010/00133]\tTime 0.46 (0.46)\tLoss 0.74 (0.74)\n",
            "\t\tcls_loss 0.46 (0.46)\treg_loss 0.28 (0.28)\n",
            "Epoch: [013][00020/00133]\tTime 0.38 (0.42)\tLoss 0.77 (0.75)\n",
            "\t\tcls_loss 0.49 (0.47)\treg_loss 0.28 (0.28)\n",
            "Epoch: [013][00030/00133]\tTime 0.41 (0.42)\tLoss 0.65 (0.72)\n",
            "\t\tcls_loss 0.40 (0.45)\treg_loss 0.25 (0.27)\n",
            "Epoch: [013][00040/00133]\tTime 0.41 (0.42)\tLoss 0.75 (0.73)\n",
            "\t\tcls_loss 0.46 (0.45)\treg_loss 0.29 (0.27)\n",
            "Epoch: [013][00050/00133]\tTime 0.37 (0.41)\tLoss 0.73 (0.73)\n",
            "\t\tcls_loss 0.44 (0.45)\treg_loss 0.30 (0.28)\n",
            "Epoch: [013][00060/00133]\tTime 0.38 (0.40)\tLoss 0.69 (0.72)\n",
            "\t\tcls_loss 0.41 (0.44)\treg_loss 0.28 (0.28)\n",
            "Epoch: [013][00070/00133]\tTime 0.43 (0.41)\tLoss 0.98 (0.76)\n",
            "\t\tcls_loss 0.58 (0.46)\treg_loss 0.40 (0.30)\n",
            "Epoch: [013][00080/00133]\tTime 0.38 (0.40)\tLoss 0.83 (0.77)\n",
            "\t\tcls_loss 0.51 (0.47)\treg_loss 0.32 (0.30)\n",
            "Epoch: [013][00090/00133]\tTime 0.39 (0.40)\tLoss 0.87 (0.78)\n",
            "\t\tcls_loss 0.55 (0.48)\treg_loss 0.32 (0.30)\n",
            "Epoch: [013][00100/00133]\tTime 0.43 (0.40)\tLoss 0.67 (0.77)\n",
            "\t\tcls_loss 0.41 (0.47)\treg_loss 0.26 (0.30)\n",
            "Epoch: [013][00110/00133]\tTime 0.38 (0.40)\tLoss 0.74 (0.77)\n",
            "\t\tcls_loss 0.46 (0.47)\treg_loss 0.28 (0.30)\n",
            "Epoch: [013][00120/00133]\tTime 0.38 (0.40)\tLoss 0.86 (0.77)\n",
            "\t\tcls_loss 0.55 (0.48)\treg_loss 0.31 (0.30)\n",
            "Epoch: [013][00130/00133]\tTime 0.39 (0.40)\tLoss 0.94 (0.79)\n",
            "\t\tcls_loss 0.57 (0.48)\treg_loss 0.37 (0.30)\n",
            "[Train]: Epoch 13 finished with lr=0.00079389\n",
            "\n",
            "\n",
            "[Train]: Epoch 14 started\n",
            "Epoch: [014][00010/00133]\tTime 0.43 (0.43)\tLoss 0.68 (0.68)\n",
            "\t\tcls_loss 0.41 (0.41)\treg_loss 0.27 (0.27)\n",
            "Epoch: [014][00020/00133]\tTime 0.38 (0.40)\tLoss 0.71 (0.70)\n",
            "\t\tcls_loss 0.43 (0.42)\treg_loss 0.28 (0.28)\n",
            "Epoch: [014][00030/00133]\tTime 0.46 (0.42)\tLoss 0.83 (0.74)\n",
            "\t\tcls_loss 0.50 (0.45)\treg_loss 0.32 (0.29)\n",
            "Epoch: [014][00040/00133]\tTime 0.39 (0.41)\tLoss 0.74 (0.74)\n",
            "\t\tcls_loss 0.47 (0.45)\treg_loss 0.27 (0.29)\n",
            "Epoch: [014][00050/00133]\tTime 0.38 (0.41)\tLoss 0.78 (0.75)\n",
            "\t\tcls_loss 0.50 (0.46)\treg_loss 0.28 (0.29)\n",
            "Epoch: [014][00060/00133]\tTime 0.40 (0.41)\tLoss 0.75 (0.75)\n",
            "\t\tcls_loss 0.46 (0.46)\treg_loss 0.29 (0.29)\n",
            "Epoch: [014][00070/00133]\tTime 0.41 (0.41)\tLoss 0.82 (0.76)\n",
            "\t\tcls_loss 0.51 (0.47)\treg_loss 0.31 (0.29)\n",
            "Epoch: [014][00080/00133]\tTime 0.37 (0.40)\tLoss 0.66 (0.75)\n",
            "\t\tcls_loss 0.41 (0.46)\treg_loss 0.25 (0.29)\n",
            "Epoch: [014][00090/00133]\tTime 0.38 (0.40)\tLoss 0.56 (0.73)\n",
            "\t\tcls_loss 0.36 (0.45)\treg_loss 0.20 (0.28)\n",
            "Epoch: [014][00100/00133]\tTime 0.46 (0.40)\tLoss 0.69 (0.72)\n",
            "\t\tcls_loss 0.41 (0.45)\treg_loss 0.28 (0.28)\n",
            "Epoch: [014][00110/00133]\tTime 0.39 (0.40)\tLoss 0.83 (0.73)\n",
            "\t\tcls_loss 0.51 (0.45)\treg_loss 0.32 (0.28)\n",
            "Epoch: [014][00120/00133]\tTime 0.38 (0.40)\tLoss 0.79 (0.74)\n",
            "\t\tcls_loss 0.49 (0.46)\treg_loss 0.30 (0.28)\n",
            "Epoch: [014][00130/00133]\tTime 0.44 (0.40)\tLoss 0.83 (0.75)\n",
            "\t\tcls_loss 0.50 (0.46)\treg_loss 0.33 (0.29)\n",
            "[Train]: Epoch 14 finished with lr=0.00075000\n",
            "\n",
            "\n",
            "[Train]: Epoch 15 started\n",
            "Epoch: [015][00010/00133]\tTime 0.48 (0.48)\tLoss 0.54 (0.54)\n",
            "\t\tcls_loss 0.33 (0.33)\treg_loss 0.21 (0.21)\n",
            "Epoch: [015][00020/00133]\tTime 0.38 (0.43)\tLoss 0.79 (0.66)\n",
            "\t\tcls_loss 0.46 (0.40)\treg_loss 0.32 (0.27)\n",
            "Epoch: [015][00030/00133]\tTime 0.37 (0.41)\tLoss 0.73 (0.69)\n",
            "\t\tcls_loss 0.43 (0.41)\treg_loss 0.30 (0.28)\n",
            "Epoch: [015][00040/00133]\tTime 0.41 (0.41)\tLoss 0.68 (0.68)\n",
            "\t\tcls_loss 0.43 (0.41)\treg_loss 0.25 (0.27)\n",
            "Epoch: [015][00050/00133]\tTime 0.40 (0.41)\tLoss 1.02 (0.75)\n",
            "\t\tcls_loss 0.63 (0.46)\treg_loss 0.39 (0.29)\n",
            "Epoch: [015][00060/00133]\tTime 0.40 (0.41)\tLoss 0.79 (0.76)\n",
            "\t\tcls_loss 0.49 (0.46)\treg_loss 0.30 (0.30)\n",
            "Epoch: [015][00070/00133]\tTime 0.41 (0.41)\tLoss 0.72 (0.75)\n",
            "\t\tcls_loss 0.45 (0.46)\treg_loss 0.27 (0.29)\n",
            "Epoch: [015][00080/00133]\tTime 0.42 (0.41)\tLoss 0.67 (0.74)\n",
            "\t\tcls_loss 0.42 (0.46)\treg_loss 0.26 (0.29)\n",
            "Epoch: [015][00090/00133]\tTime 0.36 (0.40)\tLoss 0.57 (0.72)\n",
            "\t\tcls_loss 0.35 (0.44)\treg_loss 0.23 (0.28)\n",
            "Epoch: [015][00100/00133]\tTime 0.37 (0.40)\tLoss 0.78 (0.73)\n",
            "\t\tcls_loss 0.47 (0.45)\treg_loss 0.30 (0.28)\n",
            "Epoch: [015][00110/00133]\tTime 0.43 (0.40)\tLoss 0.79 (0.74)\n",
            "\t\tcls_loss 0.49 (0.45)\treg_loss 0.30 (0.29)\n",
            "Epoch: [015][00120/00133]\tTime 0.38 (0.40)\tLoss 0.66 (0.73)\n",
            "\t\tcls_loss 0.40 (0.45)\treg_loss 0.25 (0.28)\n",
            "Epoch: [015][00130/00133]\tTime 0.37 (0.40)\tLoss 0.68 (0.72)\n",
            "\t\tcls_loss 0.42 (0.44)\treg_loss 0.26 (0.28)\n",
            "[Train]: Epoch 15 finished with lr=0.00070337\n",
            "\n",
            "\n",
            "[Train]: Epoch 16 started\n",
            "Epoch: [016][00010/00133]\tTime 0.49 (0.49)\tLoss 0.84 (0.84)\n",
            "\t\tcls_loss 0.51 (0.51)\treg_loss 0.33 (0.33)\n",
            "Epoch: [016][00020/00133]\tTime 0.38 (0.44)\tLoss 0.63 (0.74)\n",
            "\t\tcls_loss 0.39 (0.45)\treg_loss 0.25 (0.29)\n",
            "Epoch: [016][00030/00133]\tTime 0.37 (0.41)\tLoss 0.69 (0.72)\n",
            "\t\tcls_loss 0.39 (0.43)\treg_loss 0.30 (0.29)\n",
            "Epoch: [016][00040/00133]\tTime 0.43 (0.42)\tLoss 0.73 (0.72)\n",
            "\t\tcls_loss 0.43 (0.43)\treg_loss 0.30 (0.29)\n",
            "Epoch: [016][00050/00133]\tTime 0.36 (0.41)\tLoss 0.57 (0.69)\n",
            "\t\tcls_loss 0.35 (0.41)\treg_loss 0.21 (0.28)\n",
            "Epoch: [016][00060/00133]\tTime 0.38 (0.40)\tLoss 0.67 (0.69)\n",
            "\t\tcls_loss 0.39 (0.41)\treg_loss 0.28 (0.28)\n",
            "Epoch: [016][00070/00133]\tTime 0.41 (0.40)\tLoss 0.78 (0.70)\n",
            "\t\tcls_loss 0.48 (0.42)\treg_loss 0.30 (0.28)\n",
            "Epoch: [016][00080/00133]\tTime 0.38 (0.40)\tLoss 0.70 (0.70)\n",
            "\t\tcls_loss 0.45 (0.42)\treg_loss 0.25 (0.28)\n",
            "Epoch: [016][00090/00133]\tTime 0.37 (0.40)\tLoss 0.63 (0.69)\n",
            "\t\tcls_loss 0.39 (0.42)\treg_loss 0.24 (0.27)\n",
            "Epoch: [016][00100/00133]\tTime 0.39 (0.39)\tLoss 0.73 (0.70)\n",
            "\t\tcls_loss 0.44 (0.42)\treg_loss 0.29 (0.28)\n",
            "Epoch: [016][00110/00133]\tTime 0.40 (0.40)\tLoss 0.81 (0.71)\n",
            "\t\tcls_loss 0.51 (0.43)\treg_loss 0.30 (0.28)\n",
            "Epoch: [016][00120/00133]\tTime 0.38 (0.39)\tLoss 0.65 (0.70)\n",
            "\t\tcls_loss 0.39 (0.43)\treg_loss 0.26 (0.28)\n",
            "Epoch: [016][00130/00133]\tTime 0.35 (0.39)\tLoss 0.59 (0.69)\n",
            "\t\tcls_loss 0.37 (0.42)\treg_loss 0.21 (0.27)\n",
            "[Train]: Epoch 16 finished with lr=0.00065451\n",
            "\n",
            "\n",
            "[Train]: Epoch 17 started\n",
            "Epoch: [017][00010/00133]\tTime 0.49 (0.49)\tLoss 0.78 (0.78)\n",
            "\t\tcls_loss 0.48 (0.48)\treg_loss 0.30 (0.30)\n",
            "Epoch: [017][00020/00133]\tTime 0.37 (0.43)\tLoss 0.79 (0.78)\n",
            "\t\tcls_loss 0.48 (0.48)\treg_loss 0.31 (0.31)\n",
            "Epoch: [017][00030/00133]\tTime 0.37 (0.41)\tLoss 0.60 (0.72)\n",
            "\t\tcls_loss 0.36 (0.44)\treg_loss 0.24 (0.28)\n",
            "Epoch: [017][00040/00133]\tTime 0.43 (0.41)\tLoss 0.79 (0.74)\n",
            "\t\tcls_loss 0.47 (0.45)\treg_loss 0.31 (0.29)\n",
            "Epoch: [017][00050/00133]\tTime 0.37 (0.41)\tLoss 0.62 (0.71)\n",
            "\t\tcls_loss 0.36 (0.43)\treg_loss 0.26 (0.28)\n",
            "Epoch: [017][00060/00133]\tTime 0.39 (0.40)\tLoss 0.73 (0.72)\n",
            "\t\tcls_loss 0.45 (0.43)\treg_loss 0.28 (0.28)\n",
            "Epoch: [017][00070/00133]\tTime 0.41 (0.40)\tLoss 0.74 (0.72)\n",
            "\t\tcls_loss 0.47 (0.44)\treg_loss 0.27 (0.28)\n",
            "Epoch: [017][00080/00133]\tTime 0.37 (0.40)\tLoss 0.56 (0.70)\n",
            "\t\tcls_loss 0.35 (0.43)\treg_loss 0.21 (0.27)\n",
            "Epoch: [017][00090/00133]\tTime 0.39 (0.40)\tLoss 0.63 (0.69)\n",
            "\t\tcls_loss 0.40 (0.42)\treg_loss 0.23 (0.27)\n",
            "Epoch: [017][00100/00133]\tTime 0.41 (0.40)\tLoss 0.67 (0.69)\n",
            "\t\tcls_loss 0.39 (0.42)\treg_loss 0.28 (0.27)\n",
            "Epoch: [017][00110/00133]\tTime 0.38 (0.40)\tLoss 0.77 (0.70)\n",
            "\t\tcls_loss 0.45 (0.42)\treg_loss 0.32 (0.27)\n",
            "Epoch: [017][00120/00133]\tTime 0.36 (0.39)\tLoss 0.81 (0.71)\n",
            "\t\tcls_loss 0.48 (0.43)\treg_loss 0.33 (0.28)\n",
            "Epoch: [017][00130/00133]\tTime 0.35 (0.39)\tLoss 0.80 (0.71)\n",
            "\t\tcls_loss 0.46 (0.43)\treg_loss 0.33 (0.28)\n",
            "[Train]: Epoch 17 finished with lr=0.00060396\n",
            "\n",
            "\n",
            "[Train]: Epoch 18 started\n",
            "Epoch: [018][00010/00133]\tTime 0.48 (0.48)\tLoss 0.61 (0.61)\n",
            "\t\tcls_loss 0.37 (0.37)\treg_loss 0.24 (0.24)\n",
            "Epoch: [018][00020/00133]\tTime 0.39 (0.43)\tLoss 0.59 (0.60)\n",
            "\t\tcls_loss 0.36 (0.37)\treg_loss 0.23 (0.23)\n",
            "Epoch: [018][00030/00133]\tTime 0.39 (0.42)\tLoss 0.68 (0.63)\n",
            "\t\tcls_loss 0.41 (0.38)\treg_loss 0.26 (0.24)\n",
            "Epoch: [018][00040/00133]\tTime 0.41 (0.42)\tLoss 0.69 (0.64)\n",
            "\t\tcls_loss 0.43 (0.40)\treg_loss 0.26 (0.25)\n",
            "Epoch: [018][00050/00133]\tTime 0.38 (0.41)\tLoss 0.50 (0.61)\n",
            "\t\tcls_loss 0.30 (0.38)\treg_loss 0.20 (0.24)\n",
            "Epoch: [018][00060/00133]\tTime 0.37 (0.40)\tLoss 0.70 (0.63)\n",
            "\t\tcls_loss 0.44 (0.39)\treg_loss 0.26 (0.24)\n",
            "Epoch: [018][00070/00133]\tTime 0.43 (0.41)\tLoss 0.76 (0.65)\n",
            "\t\tcls_loss 0.46 (0.40)\treg_loss 0.30 (0.25)\n",
            "Epoch: [018][00080/00133]\tTime 0.37 (0.40)\tLoss 0.60 (0.64)\n",
            "\t\tcls_loss 0.37 (0.40)\treg_loss 0.23 (0.25)\n",
            "Epoch: [018][00090/00133]\tTime 0.37 (0.40)\tLoss 0.70 (0.65)\n",
            "\t\tcls_loss 0.45 (0.40)\treg_loss 0.25 (0.25)\n",
            "Epoch: [018][00100/00133]\tTime 0.44 (0.40)\tLoss 0.87 (0.67)\n",
            "\t\tcls_loss 0.55 (0.42)\treg_loss 0.32 (0.25)\n",
            "Epoch: [018][00110/00133]\tTime 0.37 (0.40)\tLoss 0.75 (0.68)\n",
            "\t\tcls_loss 0.44 (0.42)\treg_loss 0.31 (0.26)\n",
            "Epoch: [018][00120/00133]\tTime 0.37 (0.40)\tLoss 0.62 (0.67)\n",
            "\t\tcls_loss 0.38 (0.42)\treg_loss 0.24 (0.26)\n",
            "Epoch: [018][00130/00133]\tTime 0.42 (0.40)\tLoss 0.75 (0.68)\n",
            "\t\tcls_loss 0.45 (0.42)\treg_loss 0.31 (0.26)\n",
            "[Train]: Epoch 18 finished with lr=0.00055227\n",
            "\n",
            "\n",
            "[Train]: Epoch 19 started\n",
            "Epoch: [019][00010/00133]\tTime 0.43 (0.43)\tLoss 0.44 (0.44)\n",
            "\t\tcls_loss 0.26 (0.26)\treg_loss 0.18 (0.18)\n",
            "Epoch: [019][00020/00133]\tTime 0.37 (0.40)\tLoss 0.66 (0.55)\n",
            "\t\tcls_loss 0.42 (0.34)\treg_loss 0.25 (0.21)\n",
            "Epoch: [019][00030/00133]\tTime 0.43 (0.41)\tLoss 0.69 (0.60)\n",
            "\t\tcls_loss 0.42 (0.37)\treg_loss 0.27 (0.23)\n",
            "Epoch: [019][00040/00133]\tTime 0.38 (0.40)\tLoss 0.60 (0.60)\n",
            "\t\tcls_loss 0.38 (0.37)\treg_loss 0.22 (0.23)\n",
            "Epoch: [019][00050/00133]\tTime 0.38 (0.40)\tLoss 0.44 (0.57)\n",
            "\t\tcls_loss 0.27 (0.35)\treg_loss 0.17 (0.22)\n",
            "Epoch: [019][00060/00133]\tTime 0.39 (0.39)\tLoss 0.54 (0.56)\n",
            "\t\tcls_loss 0.31 (0.34)\treg_loss 0.22 (0.22)\n",
            "Epoch: [019][00070/00133]\tTime 0.40 (0.40)\tLoss 0.89 (0.61)\n",
            "\t\tcls_loss 0.51 (0.37)\treg_loss 0.38 (0.24)\n",
            "Epoch: [019][00080/00133]\tTime 0.38 (0.39)\tLoss 0.62 (0.61)\n",
            "\t\tcls_loss 0.37 (0.37)\treg_loss 0.24 (0.24)\n",
            "Epoch: [019][00090/00133]\tTime 0.40 (0.39)\tLoss 0.65 (0.61)\n",
            "\t\tcls_loss 0.41 (0.37)\treg_loss 0.25 (0.24)\n",
            "Epoch: [019][00100/00133]\tTime 0.45 (0.40)\tLoss 0.68 (0.62)\n",
            "\t\tcls_loss 0.40 (0.38)\treg_loss 0.28 (0.25)\n",
            "Epoch: [019][00110/00133]\tTime 0.37 (0.40)\tLoss 0.73 (0.63)\n",
            "\t\tcls_loss 0.41 (0.38)\treg_loss 0.32 (0.25)\n",
            "Epoch: [019][00120/00133]\tTime 0.37 (0.39)\tLoss 0.78 (0.64)\n",
            "\t\tcls_loss 0.47 (0.39)\treg_loss 0.31 (0.26)\n",
            "Epoch: [019][00130/00133]\tTime 0.42 (0.40)\tLoss 0.47 (0.63)\n",
            "\t\tcls_loss 0.30 (0.38)\treg_loss 0.18 (0.25)\n",
            "[Train]: Epoch 19 finished with lr=0.00050001\n",
            "\n",
            "\n",
            "[Train]: Epoch 20 started\n",
            "Epoch: [020][00010/00133]\tTime 0.43 (0.43)\tLoss 0.61 (0.61)\n",
            "\t\tcls_loss 0.36 (0.36)\treg_loss 0.24 (0.24)\n",
            "Epoch: [020][00020/00133]\tTime 0.39 (0.41)\tLoss 0.73 (0.67)\n",
            "\t\tcls_loss 0.43 (0.40)\treg_loss 0.31 (0.28)\n",
            "Epoch: [020][00030/00133]\tTime 0.41 (0.41)\tLoss 0.79 (0.71)\n",
            "\t\tcls_loss 0.47 (0.42)\treg_loss 0.32 (0.29)\n",
            "Epoch: [020][00040/00133]\tTime 0.37 (0.40)\tLoss 0.58 (0.68)\n",
            "\t\tcls_loss 0.35 (0.40)\treg_loss 0.23 (0.28)\n",
            "Epoch: [020][00050/00133]\tTime 0.40 (0.40)\tLoss 0.68 (0.68)\n",
            "\t\tcls_loss 0.42 (0.41)\treg_loss 0.27 (0.27)\n",
            "Epoch: [020][00060/00133]\tTime 0.41 (0.40)\tLoss 0.61 (0.67)\n",
            "\t\tcls_loss 0.38 (0.40)\treg_loss 0.23 (0.27)\n",
            "Epoch: [020][00070/00133]\tTime 0.37 (0.40)\tLoss 0.83 (0.69)\n",
            "\t\tcls_loss 0.51 (0.42)\treg_loss 0.32 (0.27)\n",
            "Epoch: [020][00080/00133]\tTime 0.38 (0.39)\tLoss 0.46 (0.66)\n",
            "\t\tcls_loss 0.31 (0.40)\treg_loss 0.16 (0.26)\n",
            "Epoch: [020][00090/00133]\tTime 0.44 (0.40)\tLoss 0.56 (0.65)\n",
            "\t\tcls_loss 0.33 (0.40)\treg_loss 0.22 (0.25)\n",
            "Epoch: [020][00100/00133]\tTime 0.37 (0.40)\tLoss 0.73 (0.66)\n",
            "\t\tcls_loss 0.43 (0.40)\treg_loss 0.30 (0.26)\n",
            "Epoch: [020][00110/00133]\tTime 0.37 (0.39)\tLoss 0.61 (0.65)\n",
            "\t\tcls_loss 0.38 (0.40)\treg_loss 0.23 (0.26)\n",
            "Epoch: [020][00120/00133]\tTime 0.42 (0.40)\tLoss 0.75 (0.66)\n",
            "\t\tcls_loss 0.44 (0.40)\treg_loss 0.30 (0.26)\n",
            "Epoch: [020][00130/00133]\tTime 0.38 (0.40)\tLoss 0.73 (0.67)\n",
            "\t\tcls_loss 0.44 (0.40)\treg_loss 0.29 (0.26)\n",
            "[Train]: Epoch 20 finished with lr=0.00044774\n",
            "\n",
            "\n",
            "[Train]: Epoch 21 started\n",
            "Epoch: [021][00010/00133]\tTime 0.43 (0.43)\tLoss 0.78 (0.78)\n",
            "\t\tcls_loss 0.48 (0.48)\treg_loss 0.31 (0.31)\n",
            "Epoch: [021][00020/00133]\tTime 0.43 (0.43)\tLoss 0.43 (0.61)\n",
            "\t\tcls_loss 0.26 (0.37)\treg_loss 0.17 (0.24)\n",
            "Epoch: [021][00030/00133]\tTime 0.37 (0.41)\tLoss 0.80 (0.67)\n",
            "\t\tcls_loss 0.48 (0.41)\treg_loss 0.32 (0.27)\n",
            "Epoch: [021][00040/00133]\tTime 0.38 (0.40)\tLoss 0.64 (0.66)\n",
            "\t\tcls_loss 0.37 (0.40)\treg_loss 0.26 (0.26)\n",
            "Epoch: [021][00050/00133]\tTime 0.44 (0.41)\tLoss 0.75 (0.68)\n",
            "\t\tcls_loss 0.46 (0.41)\treg_loss 0.30 (0.27)\n",
            "Epoch: [021][00060/00133]\tTime 0.44 (0.41)\tLoss 0.66 (0.68)\n",
            "\t\tcls_loss 0.38 (0.41)\treg_loss 0.28 (0.27)\n",
            "Epoch: [021][00070/00133]\tTime 0.39 (0.41)\tLoss 0.64 (0.67)\n",
            "\t\tcls_loss 0.39 (0.40)\treg_loss 0.25 (0.27)\n",
            "Epoch: [021][00080/00133]\tTime 0.42 (0.41)\tLoss 0.58 (0.66)\n",
            "\t\tcls_loss 0.35 (0.40)\treg_loss 0.23 (0.26)\n",
            "Epoch: [021][00090/00133]\tTime 0.40 (0.41)\tLoss 0.60 (0.65)\n",
            "\t\tcls_loss 0.36 (0.39)\treg_loss 0.24 (0.26)\n",
            "Epoch: [021][00100/00133]\tTime 0.41 (0.41)\tLoss 0.63 (0.65)\n",
            "\t\tcls_loss 0.37 (0.39)\treg_loss 0.26 (0.26)\n",
            "Epoch: [021][00110/00133]\tTime 0.38 (0.41)\tLoss 0.61 (0.65)\n",
            "\t\tcls_loss 0.36 (0.39)\treg_loss 0.25 (0.26)\n",
            "Epoch: [021][00120/00133]\tTime 0.42 (0.41)\tLoss 0.71 (0.65)\n",
            "\t\tcls_loss 0.41 (0.39)\treg_loss 0.30 (0.26)\n",
            "Epoch: [021][00130/00133]\tTime 0.40 (0.41)\tLoss 0.64 (0.65)\n",
            "\t\tcls_loss 0.36 (0.39)\treg_loss 0.27 (0.26)\n",
            "[Train]: Epoch 21 finished with lr=0.00039605\n",
            "\n",
            "\n",
            "[Train]: Epoch 22 started\n",
            "Epoch: [022][00010/00133]\tTime 0.48 (0.48)\tLoss 0.65 (0.65)\n",
            "\t\tcls_loss 0.39 (0.39)\treg_loss 0.27 (0.27)\n",
            "Epoch: [022][00020/00133]\tTime 0.40 (0.44)\tLoss 0.63 (0.64)\n",
            "\t\tcls_loss 0.35 (0.37)\treg_loss 0.28 (0.27)\n",
            "Epoch: [022][00030/00133]\tTime 0.41 (0.43)\tLoss 0.55 (0.61)\n",
            "\t\tcls_loss 0.35 (0.36)\treg_loss 0.20 (0.25)\n",
            "Epoch: [022][00040/00133]\tTime 0.41 (0.42)\tLoss 0.62 (0.61)\n",
            "\t\tcls_loss 0.38 (0.37)\treg_loss 0.24 (0.25)\n",
            "Epoch: [022][00050/00133]\tTime 0.44 (0.43)\tLoss 0.77 (0.65)\n",
            "\t\tcls_loss 0.46 (0.38)\treg_loss 0.32 (0.26)\n",
            "Epoch: [022][00060/00133]\tTime 0.37 (0.42)\tLoss 0.71 (0.66)\n",
            "\t\tcls_loss 0.43 (0.39)\treg_loss 0.28 (0.26)\n",
            "Epoch: [022][00070/00133]\tTime 0.38 (0.41)\tLoss 0.52 (0.64)\n",
            "\t\tcls_loss 0.30 (0.38)\treg_loss 0.22 (0.26)\n",
            "Epoch: [022][00080/00133]\tTime 0.45 (0.42)\tLoss 0.59 (0.63)\n",
            "\t\tcls_loss 0.32 (0.37)\treg_loss 0.27 (0.26)\n",
            "Epoch: [022][00090/00133]\tTime 0.41 (0.42)\tLoss 0.62 (0.63)\n",
            "\t\tcls_loss 0.37 (0.37)\treg_loss 0.25 (0.26)\n",
            "Epoch: [022][00100/00133]\tTime 0.38 (0.41)\tLoss 0.58 (0.62)\n",
            "\t\tcls_loss 0.32 (0.37)\treg_loss 0.27 (0.26)\n",
            "Epoch: [022][00110/00133]\tTime 0.45 (0.42)\tLoss 0.76 (0.64)\n",
            "\t\tcls_loss 0.45 (0.37)\treg_loss 0.31 (0.26)\n",
            "Epoch: [022][00120/00133]\tTime 0.39 (0.42)\tLoss 0.70 (0.64)\n",
            "\t\tcls_loss 0.41 (0.38)\treg_loss 0.29 (0.27)\n",
            "Epoch: [022][00130/00133]\tTime 0.36 (0.41)\tLoss 0.59 (0.64)\n",
            "\t\tcls_loss 0.36 (0.37)\treg_loss 0.24 (0.26)\n",
            "[Train]: Epoch 22 finished with lr=0.00034550\n",
            "\n",
            "\n",
            "[Train]: Epoch 23 started\n",
            "Epoch: [023][00010/00133]\tTime 0.50 (0.50)\tLoss 0.50 (0.50)\n",
            "\t\tcls_loss 0.29 (0.29)\treg_loss 0.22 (0.22)\n",
            "Epoch: [023][00020/00133]\tTime 0.41 (0.45)\tLoss 0.64 (0.57)\n",
            "\t\tcls_loss 0.40 (0.34)\treg_loss 0.24 (0.23)\n",
            "Epoch: [023][00030/00133]\tTime 0.38 (0.43)\tLoss 0.78 (0.64)\n",
            "\t\tcls_loss 0.45 (0.38)\treg_loss 0.32 (0.26)\n",
            "Epoch: [023][00040/00133]\tTime 0.47 (0.44)\tLoss 0.51 (0.61)\n",
            "\t\tcls_loss 0.32 (0.36)\treg_loss 0.19 (0.24)\n",
            "Epoch: [023][00050/00133]\tTime 0.40 (0.43)\tLoss 0.60 (0.61)\n",
            "\t\tcls_loss 0.35 (0.36)\treg_loss 0.25 (0.24)\n",
            "Epoch: [023][00060/00133]\tTime 0.38 (0.42)\tLoss 0.65 (0.61)\n",
            "\t\tcls_loss 0.39 (0.37)\treg_loss 0.26 (0.25)\n",
            "Epoch: [023][00070/00133]\tTime 0.44 (0.43)\tLoss 0.79 (0.64)\n",
            "\t\tcls_loss 0.47 (0.38)\treg_loss 0.33 (0.26)\n",
            "Epoch: [023][00080/00133]\tTime 0.40 (0.42)\tLoss 0.53 (0.62)\n",
            "\t\tcls_loss 0.32 (0.37)\treg_loss 0.21 (0.25)\n",
            "Epoch: [023][00090/00133]\tTime 0.38 (0.42)\tLoss 0.68 (0.63)\n",
            "\t\tcls_loss 0.44 (0.38)\treg_loss 0.24 (0.25)\n",
            "Epoch: [023][00100/00133]\tTime 0.43 (0.42)\tLoss 0.82 (0.65)\n",
            "\t\tcls_loss 0.49 (0.39)\treg_loss 0.34 (0.26)\n",
            "Epoch: [023][00110/00133]\tTime 0.40 (0.42)\tLoss 0.57 (0.64)\n",
            "\t\tcls_loss 0.34 (0.39)\treg_loss 0.23 (0.26)\n",
            "Epoch: [023][00120/00133]\tTime 0.39 (0.41)\tLoss 0.75 (0.65)\n",
            "\t\tcls_loss 0.46 (0.39)\treg_loss 0.29 (0.26)\n",
            "Epoch: [023][00130/00133]\tTime 0.40 (0.41)\tLoss 0.75 (0.66)\n",
            "\t\tcls_loss 0.46 (0.40)\treg_loss 0.28 (0.26)\n",
            "[Train]: Epoch 23 finished with lr=0.00029664\n",
            "\n",
            "\n",
            "[Train]: Epoch 24 started\n",
            "Epoch: [024][00010/00133]\tTime 0.45 (0.45)\tLoss 0.62 (0.62)\n",
            "\t\tcls_loss 0.38 (0.38)\treg_loss 0.24 (0.24)\n",
            "Epoch: [024][00020/00133]\tTime 0.40 (0.43)\tLoss 0.53 (0.57)\n",
            "\t\tcls_loss 0.31 (0.34)\treg_loss 0.22 (0.23)\n",
            "Epoch: [024][00030/00133]\tTime 0.45 (0.43)\tLoss 0.85 (0.66)\n",
            "\t\tcls_loss 0.50 (0.40)\treg_loss 0.35 (0.27)\n",
            "Epoch: [024][00040/00133]\tTime 0.39 (0.42)\tLoss 0.48 (0.62)\n",
            "\t\tcls_loss 0.30 (0.37)\treg_loss 0.19 (0.25)\n",
            "Epoch: [024][00050/00133]\tTime 0.38 (0.41)\tLoss 0.62 (0.62)\n",
            "\t\tcls_loss 0.37 (0.37)\treg_loss 0.25 (0.25)\n",
            "Epoch: [024][00060/00133]\tTime 0.39 (0.41)\tLoss 0.73 (0.64)\n",
            "\t\tcls_loss 0.45 (0.39)\treg_loss 0.27 (0.25)\n",
            "Epoch: [024][00070/00133]\tTime 0.44 (0.41)\tLoss 0.49 (0.62)\n",
            "\t\tcls_loss 0.28 (0.37)\treg_loss 0.20 (0.24)\n",
            "Epoch: [024][00080/00133]\tTime 0.38 (0.41)\tLoss 0.68 (0.62)\n",
            "\t\tcls_loss 0.42 (0.38)\treg_loss 0.26 (0.25)\n",
            "Epoch: [024][00090/00133]\tTime 0.42 (0.41)\tLoss 0.53 (0.61)\n",
            "\t\tcls_loss 0.33 (0.37)\treg_loss 0.20 (0.24)\n",
            "Epoch: [024][00100/00133]\tTime 0.42 (0.41)\tLoss 0.64 (0.62)\n",
            "\t\tcls_loss 0.37 (0.37)\treg_loss 0.27 (0.24)\n",
            "Epoch: [024][00110/00133]\tTime 0.40 (0.41)\tLoss 0.66 (0.62)\n",
            "\t\tcls_loss 0.39 (0.37)\treg_loss 0.28 (0.25)\n",
            "Epoch: [024][00120/00133]\tTime 0.41 (0.41)\tLoss 0.54 (0.61)\n",
            "\t\tcls_loss 0.33 (0.37)\treg_loss 0.21 (0.24)\n",
            "Epoch: [024][00130/00133]\tTime 0.44 (0.41)\tLoss 0.64 (0.62)\n",
            "\t\tcls_loss 0.39 (0.37)\treg_loss 0.25 (0.25)\n",
            "[Train]: Epoch 24 finished with lr=0.00025001\n",
            "\n",
            "\n",
            "[Train]: Epoch 25 started\n",
            "Epoch: [025][00010/00133]\tTime 0.46 (0.46)\tLoss 0.43 (0.43)\n",
            "\t\tcls_loss 0.26 (0.26)\treg_loss 0.17 (0.17)\n",
            "Epoch: [025][00020/00133]\tTime 0.44 (0.45)\tLoss 0.72 (0.58)\n",
            "\t\tcls_loss 0.38 (0.32)\treg_loss 0.35 (0.26)\n",
            "Epoch: [025][00030/00133]\tTime 0.43 (0.45)\tLoss 0.44 (0.53)\n",
            "\t\tcls_loss 0.27 (0.30)\treg_loss 0.16 (0.23)\n",
            "Epoch: [025][00040/00133]\tTime 0.38 (0.43)\tLoss 0.76 (0.59)\n",
            "\t\tcls_loss 0.43 (0.34)\treg_loss 0.33 (0.25)\n",
            "Epoch: [025][00050/00133]\tTime 0.41 (0.43)\tLoss 0.46 (0.56)\n",
            "\t\tcls_loss 0.28 (0.33)\treg_loss 0.18 (0.24)\n",
            "Epoch: [025][00060/00133]\tTime 0.45 (0.43)\tLoss 0.42 (0.54)\n",
            "\t\tcls_loss 0.25 (0.31)\treg_loss 0.18 (0.23)\n",
            "Epoch: [025][00070/00133]\tTime 0.40 (0.43)\tLoss 0.54 (0.54)\n",
            "\t\tcls_loss 0.31 (0.31)\treg_loss 0.23 (0.23)\n",
            "Epoch: [025][00080/00133]\tTime 0.41 (0.42)\tLoss 0.58 (0.54)\n",
            "\t\tcls_loss 0.34 (0.32)\treg_loss 0.24 (0.23)\n",
            "Epoch: [025][00090/00133]\tTime 0.43 (0.42)\tLoss 0.71 (0.56)\n",
            "\t\tcls_loss 0.39 (0.32)\treg_loss 0.32 (0.24)\n",
            "Epoch: [025][00100/00133]\tTime 0.38 (0.42)\tLoss 0.43 (0.55)\n",
            "\t\tcls_loss 0.27 (0.32)\treg_loss 0.16 (0.23)\n",
            "Epoch: [025][00110/00133]\tTime 0.41 (0.42)\tLoss 0.52 (0.55)\n",
            "\t\tcls_loss 0.28 (0.31)\treg_loss 0.24 (0.23)\n",
            "Epoch: [025][00120/00133]\tTime 0.45 (0.42)\tLoss 0.66 (0.56)\n",
            "\t\tcls_loss 0.38 (0.32)\treg_loss 0.28 (0.24)\n",
            "Epoch: [025][00130/00133]\tTime 0.39 (0.42)\tLoss 0.48 (0.55)\n",
            "\t\tcls_loss 0.29 (0.32)\treg_loss 0.18 (0.23)\n",
            "[Train]: Epoch 25 finished with lr=0.00020612\n",
            "\n",
            "\n",
            "[Train]: Epoch 26 started\n",
            "Epoch: [026][00010/00133]\tTime 0.45 (0.45)\tLoss 0.49 (0.49)\n",
            "\t\tcls_loss 0.30 (0.30)\treg_loss 0.19 (0.19)\n",
            "Epoch: [026][00020/00133]\tTime 0.41 (0.43)\tLoss 0.50 (0.49)\n",
            "\t\tcls_loss 0.29 (0.30)\treg_loss 0.20 (0.19)\n",
            "Epoch: [026][00030/00133]\tTime 0.38 (0.41)\tLoss 0.59 (0.52)\n",
            "\t\tcls_loss 0.37 (0.32)\treg_loss 0.22 (0.20)\n",
            "Epoch: [026][00040/00133]\tTime 0.38 (0.40)\tLoss 0.60 (0.54)\n",
            "\t\tcls_loss 0.34 (0.33)\treg_loss 0.26 (0.22)\n",
            "Epoch: [026][00050/00133]\tTime 0.49 (0.42)\tLoss 0.53 (0.54)\n",
            "\t\tcls_loss 0.30 (0.32)\treg_loss 0.23 (0.22)\n",
            "Epoch: [026][00060/00133]\tTime 0.40 (0.42)\tLoss 0.34 (0.51)\n",
            "\t\tcls_loss 0.20 (0.30)\treg_loss 0.14 (0.21)\n",
            "Epoch: [026][00070/00133]\tTime 0.39 (0.41)\tLoss 0.46 (0.50)\n",
            "\t\tcls_loss 0.25 (0.29)\treg_loss 0.20 (0.21)\n",
            "Epoch: [026][00080/00133]\tTime 0.48 (0.42)\tLoss 0.52 (0.50)\n",
            "\t\tcls_loss 0.31 (0.30)\treg_loss 0.21 (0.21)\n",
            "Epoch: [026][00090/00133]\tTime 0.40 (0.42)\tLoss 0.39 (0.49)\n",
            "\t\tcls_loss 0.24 (0.29)\treg_loss 0.16 (0.20)\n",
            "Epoch: [026][00100/00133]\tTime 0.37 (0.41)\tLoss 0.62 (0.50)\n",
            "\t\tcls_loss 0.34 (0.29)\treg_loss 0.28 (0.21)\n",
            "Epoch: [026][00110/00133]\tTime 0.45 (0.42)\tLoss 0.59 (0.51)\n",
            "\t\tcls_loss 0.36 (0.30)\treg_loss 0.24 (0.21)\n",
            "Epoch: [026][00120/00133]\tTime 0.39 (0.41)\tLoss 0.66 (0.52)\n",
            "\t\tcls_loss 0.40 (0.31)\treg_loss 0.27 (0.22)\n",
            "Epoch: [026][00130/00133]\tTime 0.38 (0.41)\tLoss 0.51 (0.52)\n",
            "\t\tcls_loss 0.30 (0.31)\treg_loss 0.21 (0.22)\n",
            "[Train]: Epoch 26 finished with lr=0.00016544\n",
            "\n",
            "\n",
            "[Train]: Epoch 27 started\n",
            "Epoch: [027][00010/00133]\tTime 0.49 (0.49)\tLoss 0.43 (0.43)\n",
            "\t\tcls_loss 0.26 (0.26)\treg_loss 0.17 (0.17)\n",
            "Epoch: [027][00020/00133]\tTime 0.40 (0.44)\tLoss 0.57 (0.50)\n",
            "\t\tcls_loss 0.34 (0.30)\treg_loss 0.23 (0.20)\n",
            "Epoch: [027][00030/00133]\tTime 0.40 (0.43)\tLoss 0.60 (0.54)\n",
            "\t\tcls_loss 0.34 (0.31)\treg_loss 0.26 (0.22)\n",
            "Epoch: [027][00040/00133]\tTime 0.46 (0.44)\tLoss 0.54 (0.54)\n",
            "\t\tcls_loss 0.29 (0.31)\treg_loss 0.25 (0.23)\n",
            "Epoch: [027][00050/00133]\tTime 0.38 (0.42)\tLoss 0.39 (0.51)\n",
            "\t\tcls_loss 0.23 (0.29)\treg_loss 0.16 (0.21)\n",
            "Epoch: [027][00060/00133]\tTime 0.39 (0.42)\tLoss 0.53 (0.51)\n",
            "\t\tcls_loss 0.32 (0.30)\treg_loss 0.20 (0.21)\n",
            "Epoch: [027][00070/00133]\tTime 0.45 (0.42)\tLoss 0.53 (0.51)\n",
            "\t\tcls_loss 0.31 (0.30)\treg_loss 0.21 (0.21)\n",
            "Epoch: [027][00080/00133]\tTime 0.39 (0.42)\tLoss 0.51 (0.51)\n",
            "\t\tcls_loss 0.30 (0.30)\treg_loss 0.21 (0.21)\n",
            "Epoch: [027][00090/00133]\tTime 0.39 (0.42)\tLoss 0.60 (0.52)\n",
            "\t\tcls_loss 0.32 (0.30)\treg_loss 0.28 (0.22)\n",
            "Epoch: [027][00100/00133]\tTime 0.44 (0.42)\tLoss 0.47 (0.52)\n",
            "\t\tcls_loss 0.28 (0.30)\treg_loss 0.19 (0.22)\n",
            "Epoch: [027][00110/00133]\tTime 0.44 (0.42)\tLoss 0.52 (0.52)\n",
            "\t\tcls_loss 0.31 (0.30)\treg_loss 0.21 (0.22)\n",
            "Epoch: [027][00120/00133]\tTime 0.38 (0.42)\tLoss 0.45 (0.51)\n",
            "\t\tcls_loss 0.26 (0.30)\treg_loss 0.19 (0.21)\n",
            "Epoch: [027][00130/00133]\tTime 0.40 (0.42)\tLoss 0.52 (0.51)\n",
            "\t\tcls_loss 0.31 (0.30)\treg_loss 0.21 (0.21)\n",
            "[Train]: Epoch 27 finished with lr=0.00012844\n",
            "\n",
            "\n",
            "[Train]: Epoch 28 started\n",
            "Epoch: [028][00010/00133]\tTime 0.46 (0.46)\tLoss 0.45 (0.45)\n",
            "\t\tcls_loss 0.25 (0.25)\treg_loss 0.20 (0.20)\n",
            "Epoch: [028][00020/00133]\tTime 0.40 (0.43)\tLoss 0.51 (0.48)\n",
            "\t\tcls_loss 0.30 (0.27)\treg_loss 0.20 (0.20)\n",
            "Epoch: [028][00030/00133]\tTime 0.45 (0.44)\tLoss 0.34 (0.43)\n",
            "\t\tcls_loss 0.20 (0.25)\treg_loss 0.14 (0.18)\n",
            "Epoch: [028][00040/00133]\tTime 0.39 (0.42)\tLoss 0.53 (0.45)\n",
            "\t\tcls_loss 0.31 (0.26)\treg_loss 0.22 (0.19)\n",
            "Epoch: [028][00050/00133]\tTime 0.36 (0.41)\tLoss 0.57 (0.48)\n",
            "\t\tcls_loss 0.32 (0.27)\treg_loss 0.25 (0.20)\n",
            "Epoch: [028][00060/00133]\tTime 0.48 (0.42)\tLoss 0.53 (0.49)\n",
            "\t\tcls_loss 0.32 (0.28)\treg_loss 0.21 (0.20)\n",
            "Epoch: [028][00070/00133]\tTime 0.40 (0.42)\tLoss 0.48 (0.49)\n",
            "\t\tcls_loss 0.29 (0.28)\treg_loss 0.19 (0.20)\n",
            "Epoch: [028][00080/00133]\tTime 0.40 (0.42)\tLoss 0.43 (0.48)\n",
            "\t\tcls_loss 0.27 (0.28)\treg_loss 0.16 (0.20)\n",
            "Epoch: [028][00090/00133]\tTime 0.44 (0.42)\tLoss 0.44 (0.48)\n",
            "\t\tcls_loss 0.29 (0.28)\treg_loss 0.15 (0.19)\n",
            "Epoch: [028][00100/00133]\tTime 0.42 (0.42)\tLoss 0.57 (0.48)\n",
            "\t\tcls_loss 0.33 (0.29)\treg_loss 0.23 (0.20)\n",
            "Epoch: [028][00110/00133]\tTime 0.37 (0.42)\tLoss 0.54 (0.49)\n",
            "\t\tcls_loss 0.33 (0.29)\treg_loss 0.21 (0.20)\n",
            "Epoch: [028][00120/00133]\tTime 0.40 (0.41)\tLoss 0.69 (0.51)\n",
            "\t\tcls_loss 0.38 (0.30)\treg_loss 0.31 (0.21)\n",
            "Epoch: [028][00130/00133]\tTime 0.41 (0.41)\tLoss 0.46 (0.50)\n",
            "\t\tcls_loss 0.26 (0.30)\treg_loss 0.20 (0.21)\n",
            "[Train]: Epoch 28 finished with lr=0.00009550\n",
            "\n",
            "\n",
            "[Train]: Epoch 29 started\n",
            "Epoch: [029][00010/00133]\tTime 0.46 (0.46)\tLoss 0.53 (0.53)\n",
            "\t\tcls_loss 0.31 (0.31)\treg_loss 0.22 (0.22)\n",
            "Epoch: [029][00020/00133]\tTime 0.41 (0.44)\tLoss 0.54 (0.53)\n",
            "\t\tcls_loss 0.33 (0.32)\treg_loss 0.21 (0.21)\n",
            "Epoch: [029][00030/00133]\tTime 0.43 (0.43)\tLoss 0.54 (0.54)\n",
            "\t\tcls_loss 0.32 (0.32)\treg_loss 0.22 (0.22)\n",
            "Epoch: [029][00040/00133]\tTime 0.42 (0.43)\tLoss 0.36 (0.49)\n",
            "\t\tcls_loss 0.21 (0.29)\treg_loss 0.15 (0.20)\n",
            "Epoch: [029][00050/00133]\tTime 0.41 (0.43)\tLoss 0.47 (0.49)\n",
            "\t\tcls_loss 0.27 (0.29)\treg_loss 0.20 (0.20)\n",
            "Epoch: [029][00060/00133]\tTime 0.44 (0.43)\tLoss 0.56 (0.50)\n",
            "\t\tcls_loss 0.33 (0.29)\treg_loss 0.23 (0.21)\n",
            "Epoch: [029][00070/00133]\tTime 0.39 (0.42)\tLoss 0.45 (0.49)\n",
            "\t\tcls_loss 0.25 (0.29)\treg_loss 0.20 (0.20)\n",
            "Epoch: [029][00080/00133]\tTime 0.41 (0.42)\tLoss 0.60 (0.51)\n",
            "\t\tcls_loss 0.35 (0.30)\treg_loss 0.25 (0.21)\n",
            "Epoch: [029][00090/00133]\tTime 0.43 (0.42)\tLoss 0.54 (0.51)\n",
            "\t\tcls_loss 0.32 (0.30)\treg_loss 0.22 (0.21)\n",
            "Epoch: [029][00100/00133]\tTime 0.39 (0.42)\tLoss 0.47 (0.50)\n",
            "\t\tcls_loss 0.29 (0.30)\treg_loss 0.18 (0.21)\n",
            "Epoch: [029][00110/00133]\tTime 0.38 (0.41)\tLoss 0.52 (0.51)\n",
            "\t\tcls_loss 0.32 (0.30)\treg_loss 0.20 (0.21)\n",
            "Epoch: [029][00120/00133]\tTime 0.46 (0.42)\tLoss 0.42 (0.50)\n",
            "\t\tcls_loss 0.25 (0.30)\treg_loss 0.17 (0.20)\n",
            "Epoch: [029][00130/00133]\tTime 0.38 (0.41)\tLoss 0.55 (0.50)\n",
            "\t\tcls_loss 0.33 (0.30)\treg_loss 0.22 (0.20)\n",
            "[Train]: Epoch 29 finished with lr=0.00006700\n",
            "\n",
            "\n",
            "[Train]: Epoch 30 started\n",
            "Epoch: [030][00010/00133]\tTime 0.50 (0.50)\tLoss 0.34 (0.34)\n",
            "\t\tcls_loss 0.21 (0.21)\treg_loss 0.13 (0.13)\n",
            "Epoch: [030][00020/00133]\tTime 0.40 (0.45)\tLoss 0.62 (0.48)\n",
            "\t\tcls_loss 0.34 (0.28)\treg_loss 0.28 (0.20)\n",
            "Epoch: [030][00030/00133]\tTime 0.40 (0.43)\tLoss 0.38 (0.45)\n",
            "\t\tcls_loss 0.24 (0.27)\treg_loss 0.14 (0.18)\n",
            "Epoch: [030][00040/00133]\tTime 0.40 (0.42)\tLoss 0.66 (0.50)\n",
            "\t\tcls_loss 0.37 (0.29)\treg_loss 0.28 (0.21)\n",
            "Epoch: [030][00050/00133]\tTime 0.44 (0.43)\tLoss 0.50 (0.50)\n",
            "\t\tcls_loss 0.31 (0.30)\treg_loss 0.19 (0.20)\n",
            "Epoch: [030][00060/00133]\tTime 0.38 (0.42)\tLoss 0.69 (0.53)\n",
            "\t\tcls_loss 0.41 (0.31)\treg_loss 0.28 (0.22)\n",
            "Epoch: [030][00070/00133]\tTime 0.38 (0.41)\tLoss 0.43 (0.52)\n",
            "\t\tcls_loss 0.24 (0.30)\treg_loss 0.18 (0.21)\n",
            "Epoch: [030][00080/00133]\tTime 0.42 (0.41)\tLoss 0.37 (0.50)\n",
            "\t\tcls_loss 0.21 (0.29)\treg_loss 0.16 (0.21)\n",
            "Epoch: [030][00090/00133]\tTime 0.40 (0.41)\tLoss 0.66 (0.52)\n",
            "\t\tcls_loss 0.36 (0.30)\treg_loss 0.30 (0.22)\n",
            "Epoch: [030][00100/00133]\tTime 0.40 (0.41)\tLoss 0.38 (0.50)\n",
            "\t\tcls_loss 0.24 (0.29)\treg_loss 0.14 (0.21)\n",
            "Epoch: [030][00110/00133]\tTime 0.43 (0.41)\tLoss 0.59 (0.51)\n",
            "\t\tcls_loss 0.35 (0.30)\treg_loss 0.24 (0.21)\n",
            "Epoch: [030][00120/00133]\tTime 0.39 (0.41)\tLoss 0.42 (0.50)\n",
            "\t\tcls_loss 0.25 (0.30)\treg_loss 0.17 (0.21)\n",
            "Epoch: [030][00130/00133]\tTime 0.36 (0.41)\tLoss 0.45 (0.50)\n",
            "\t\tcls_loss 0.29 (0.30)\treg_loss 0.16 (0.20)\n",
            "[Train]: Epoch 30 finished with lr=0.00004324\n",
            "\n",
            "\n",
            "[Train]: Epoch 31 started\n",
            "Epoch: [031][00010/00133]\tTime 0.48 (0.48)\tLoss 0.54 (0.54)\n",
            "\t\tcls_loss 0.33 (0.33)\treg_loss 0.20 (0.20)\n",
            "Epoch: [031][00020/00133]\tTime 0.40 (0.44)\tLoss 0.43 (0.48)\n",
            "\t\tcls_loss 0.23 (0.28)\treg_loss 0.20 (0.20)\n",
            "Epoch: [031][00030/00133]\tTime 0.37 (0.42)\tLoss 0.57 (0.51)\n",
            "\t\tcls_loss 0.35 (0.30)\treg_loss 0.22 (0.21)\n",
            "Epoch: [031][00040/00133]\tTime 0.46 (0.43)\tLoss 0.53 (0.52)\n",
            "\t\tcls_loss 0.30 (0.30)\treg_loss 0.23 (0.21)\n",
            "Epoch: [031][00050/00133]\tTime 0.38 (0.42)\tLoss 0.53 (0.52)\n",
            "\t\tcls_loss 0.33 (0.31)\treg_loss 0.20 (0.21)\n",
            "Epoch: [031][00060/00133]\tTime 0.38 (0.41)\tLoss 0.48 (0.51)\n",
            "\t\tcls_loss 0.29 (0.31)\treg_loss 0.19 (0.21)\n",
            "Epoch: [031][00070/00133]\tTime 0.43 (0.41)\tLoss 0.51 (0.51)\n",
            "\t\tcls_loss 0.30 (0.30)\treg_loss 0.21 (0.21)\n",
            "Epoch: [031][00080/00133]\tTime 0.39 (0.41)\tLoss 0.40 (0.50)\n",
            "\t\tcls_loss 0.24 (0.30)\treg_loss 0.17 (0.20)\n",
            "Epoch: [031][00090/00133]\tTime 0.39 (0.41)\tLoss 0.49 (0.50)\n",
            "\t\tcls_loss 0.29 (0.30)\treg_loss 0.20 (0.20)\n",
            "Epoch: [031][00100/00133]\tTime 0.42 (0.41)\tLoss 0.32 (0.48)\n",
            "\t\tcls_loss 0.19 (0.29)\treg_loss 0.13 (0.20)\n",
            "Epoch: [031][00110/00133]\tTime 0.42 (0.41)\tLoss 0.49 (0.48)\n",
            "\t\tcls_loss 0.30 (0.29)\treg_loss 0.19 (0.19)\n",
            "Epoch: [031][00120/00133]\tTime 0.39 (0.41)\tLoss 0.49 (0.48)\n",
            "\t\tcls_loss 0.30 (0.29)\treg_loss 0.19 (0.19)\n",
            "Epoch: [031][00130/00133]\tTime 0.40 (0.41)\tLoss 0.53 (0.49)\n",
            "\t\tcls_loss 0.31 (0.29)\treg_loss 0.22 (0.20)\n",
            "[Train]: Epoch 31 finished with lr=0.00002448\n",
            "\n",
            "\n",
            "[Train]: Epoch 32 started\n",
            "Epoch: [032][00010/00133]\tTime 0.47 (0.47)\tLoss 0.40 (0.40)\n",
            "\t\tcls_loss 0.24 (0.24)\treg_loss 0.16 (0.16)\n",
            "Epoch: [032][00020/00133]\tTime 0.40 (0.43)\tLoss 0.43 (0.42)\n",
            "\t\tcls_loss 0.24 (0.24)\treg_loss 0.19 (0.17)\n",
            "Epoch: [032][00030/00133]\tTime 0.41 (0.42)\tLoss 0.52 (0.45)\n",
            "\t\tcls_loss 0.30 (0.26)\treg_loss 0.22 (0.19)\n",
            "Epoch: [032][00040/00133]\tTime 0.40 (0.42)\tLoss 0.50 (0.46)\n",
            "\t\tcls_loss 0.31 (0.27)\treg_loss 0.19 (0.19)\n",
            "Epoch: [032][00050/00133]\tTime 0.36 (0.41)\tLoss 0.43 (0.46)\n",
            "\t\tcls_loss 0.25 (0.27)\treg_loss 0.18 (0.19)\n",
            "Epoch: [032][00060/00133]\tTime 0.40 (0.41)\tLoss 0.50 (0.46)\n",
            "\t\tcls_loss 0.31 (0.28)\treg_loss 0.18 (0.19)\n",
            "Epoch: [032][00070/00133]\tTime 0.42 (0.41)\tLoss 0.48 (0.47)\n",
            "\t\tcls_loss 0.29 (0.28)\treg_loss 0.19 (0.19)\n",
            "Epoch: [032][00080/00133]\tTime 0.37 (0.40)\tLoss 0.36 (0.45)\n",
            "\t\tcls_loss 0.23 (0.27)\treg_loss 0.13 (0.18)\n",
            "Epoch: [032][00090/00133]\tTime 0.39 (0.40)\tLoss 0.41 (0.45)\n",
            "\t\tcls_loss 0.25 (0.27)\treg_loss 0.16 (0.18)\n",
            "Epoch: [032][00100/00133]\tTime 0.44 (0.41)\tLoss 0.36 (0.44)\n",
            "\t\tcls_loss 0.22 (0.26)\treg_loss 0.14 (0.17)\n",
            "Epoch: [032][00110/00133]\tTime 0.40 (0.41)\tLoss 0.52 (0.45)\n",
            "\t\tcls_loss 0.30 (0.27)\treg_loss 0.22 (0.18)\n",
            "Epoch: [032][00120/00133]\tTime 0.37 (0.40)\tLoss 0.39 (0.44)\n",
            "\t\tcls_loss 0.23 (0.26)\treg_loss 0.17 (0.18)\n",
            "Epoch: [032][00130/00133]\tTime 0.41 (0.40)\tLoss 0.60 (0.45)\n",
            "\t\tcls_loss 0.32 (0.27)\treg_loss 0.27 (0.18)\n",
            "[Train]: Epoch 32 finished with lr=0.00001094\n",
            "\n",
            "\n",
            "[Train]: Epoch 33 started\n",
            "Epoch: [033][00010/00133]\tTime 0.44 (0.44)\tLoss 0.51 (0.51)\n",
            "\t\tcls_loss 0.31 (0.31)\treg_loss 0.20 (0.20)\n",
            "Epoch: [033][00020/00133]\tTime 0.39 (0.41)\tLoss 0.52 (0.52)\n",
            "\t\tcls_loss 0.30 (0.31)\treg_loss 0.22 (0.21)\n",
            "Epoch: [033][00030/00133]\tTime 0.44 (0.42)\tLoss 0.49 (0.51)\n",
            "\t\tcls_loss 0.26 (0.29)\treg_loss 0.23 (0.22)\n",
            "Epoch: [033][00040/00133]\tTime 0.40 (0.42)\tLoss 0.46 (0.50)\n",
            "\t\tcls_loss 0.28 (0.29)\treg_loss 0.18 (0.21)\n",
            "Epoch: [033][00050/00133]\tTime 0.39 (0.41)\tLoss 0.49 (0.50)\n",
            "\t\tcls_loss 0.26 (0.28)\treg_loss 0.23 (0.21)\n",
            "Epoch: [033][00060/00133]\tTime 0.44 (0.42)\tLoss 0.52 (0.50)\n",
            "\t\tcls_loss 0.30 (0.29)\treg_loss 0.22 (0.21)\n",
            "Epoch: [033][00070/00133]\tTime 0.40 (0.41)\tLoss 0.51 (0.50)\n",
            "\t\tcls_loss 0.29 (0.29)\treg_loss 0.23 (0.22)\n",
            "Epoch: [033][00080/00133]\tTime 0.39 (0.41)\tLoss 0.55 (0.51)\n",
            "\t\tcls_loss 0.33 (0.29)\treg_loss 0.22 (0.22)\n",
            "Epoch: [033][00090/00133]\tTime 0.45 (0.42)\tLoss 0.37 (0.49)\n",
            "\t\tcls_loss 0.22 (0.28)\treg_loss 0.15 (0.21)\n",
            "Epoch: [033][00100/00133]\tTime 0.40 (0.41)\tLoss 0.46 (0.49)\n",
            "\t\tcls_loss 0.27 (0.28)\treg_loss 0.19 (0.21)\n",
            "Epoch: [033][00110/00133]\tTime 0.39 (0.41)\tLoss 0.40 (0.48)\n",
            "\t\tcls_loss 0.25 (0.28)\treg_loss 0.15 (0.20)\n",
            "Epoch: [033][00120/00133]\tTime 0.44 (0.41)\tLoss 0.42 (0.48)\n",
            "\t\tcls_loss 0.26 (0.28)\treg_loss 0.16 (0.20)\n",
            "Epoch: [033][00130/00133]\tTime 0.42 (0.41)\tLoss 0.49 (0.48)\n",
            "\t\tcls_loss 0.29 (0.28)\treg_loss 0.20 (0.20)\n",
            "[Train]: Epoch 33 finished with lr=0.00000275\n",
            "\n",
            "\n",
            "[Train]: Epoch 34 started\n",
            "Epoch: [034][00010/00133]\tTime 0.45 (0.45)\tLoss 0.40 (0.40)\n",
            "\t\tcls_loss 0.22 (0.22)\treg_loss 0.18 (0.18)\n",
            "Epoch: [034][00020/00133]\tTime 0.44 (0.45)\tLoss 0.58 (0.49)\n",
            "\t\tcls_loss 0.33 (0.28)\treg_loss 0.25 (0.21)\n",
            "Epoch: [034][00030/00133]\tTime 0.38 (0.43)\tLoss 0.46 (0.48)\n",
            "\t\tcls_loss 0.25 (0.27)\treg_loss 0.21 (0.21)\n",
            "Epoch: [034][00040/00133]\tTime 0.38 (0.41)\tLoss 0.51 (0.49)\n",
            "\t\tcls_loss 0.28 (0.27)\treg_loss 0.23 (0.22)\n",
            "Epoch: [034][00050/00133]\tTime 0.42 (0.42)\tLoss 0.41 (0.47)\n",
            "\t\tcls_loss 0.24 (0.27)\treg_loss 0.17 (0.21)\n",
            "Epoch: [034][00060/00133]\tTime 0.41 (0.42)\tLoss 0.40 (0.46)\n",
            "\t\tcls_loss 0.22 (0.26)\treg_loss 0.18 (0.20)\n",
            "Epoch: [034][00070/00133]\tTime 0.39 (0.41)\tLoss 0.58 (0.48)\n",
            "\t\tcls_loss 0.31 (0.27)\treg_loss 0.27 (0.21)\n",
            "Epoch: [034][00080/00133]\tTime 0.42 (0.41)\tLoss 0.57 (0.49)\n",
            "\t\tcls_loss 0.31 (0.27)\treg_loss 0.26 (0.22)\n",
            "Epoch: [034][00090/00133]\tTime 0.44 (0.42)\tLoss 0.40 (0.48)\n",
            "\t\tcls_loss 0.25 (0.27)\treg_loss 0.15 (0.21)\n",
            "Epoch: [034][00100/00133]\tTime 0.39 (0.41)\tLoss 0.43 (0.47)\n",
            "\t\tcls_loss 0.24 (0.27)\treg_loss 0.19 (0.21)\n",
            "Epoch: [034][00110/00133]\tTime 0.40 (0.41)\tLoss 0.34 (0.46)\n",
            "\t\tcls_loss 0.20 (0.26)\treg_loss 0.14 (0.20)\n",
            "Epoch: [034][00120/00133]\tTime 0.41 (0.41)\tLoss 0.25 (0.44)\n",
            "\t\tcls_loss 0.14 (0.25)\treg_loss 0.11 (0.19)\n",
            "Epoch: [034][00130/00133]\tTime 0.39 (0.41)\tLoss 0.50 (0.45)\n",
            "\t\tcls_loss 0.31 (0.26)\treg_loss 0.20 (0.19)\n",
            "[Train]: Epoch 34 finished with lr=0.00000001\n",
            "\n",
            "All done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!python eval.py configs/perception_video_valid.yaml ckpt/perception_video_train_reproduce/"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OcRUQjRMw5bp",
        "outputId": "54cc7571-a2a1-41e7-da02-2b4b1676f509"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'dataset': {'crop_ratio': [0.9, 1.0],\n",
            "             'default_fps': 15,\n",
            "             'downsample_rate': 1,\n",
            "             'feat_folder': './data/pt/action_localisation_valid_video_features',\n",
            "             'feat_stride': 16,\n",
            "             'file_ext': '.npy',\n",
            "             'file_prefix': 'v_',\n",
            "             'force_upsampling': True,\n",
            "             'input_dim': 512,\n",
            "             'input_modality': 'video',\n",
            "             'json_file': './data/pt/action_localisation_valid.json',\n",
            "             'max_seq_len': 192,\n",
            "             'mm_feat_folder': None,\n",
            "             'num_classes': 63,\n",
            "             'num_frames': 16,\n",
            "             'trunc_thresh': 0.5},\n",
            " 'dataset_name': 'perception',\n",
            " 'devices': ['cuda:0'],\n",
            " 'init_rand_seed': 1234567891,\n",
            " 'loader': {'batch_size': 16, 'num_workers': 4},\n",
            " 'model': {'backbone_arch': (2, 2, 5),\n",
            "           'backbone_type': 'convTransformer',\n",
            "           'embd_dim': 512,\n",
            "           'embd_kernel_size': 3,\n",
            "           'embd_with_ln': True,\n",
            "           'fpn_dim': 512,\n",
            "           'fpn_start_level': 0,\n",
            "           'fpn_type': 'identity',\n",
            "           'fpn_with_ln': True,\n",
            "           'head_dim': 512,\n",
            "           'head_kernel_size': 3,\n",
            "           'head_num_layers': 3,\n",
            "           'head_with_ln': True,\n",
            "           'input_dim': 512,\n",
            "           'max_buffer_len_factor': 1.0,\n",
            "           'max_seq_len': 192,\n",
            "           'n_head': 8,\n",
            "           'n_mha_win_size': [7, 7, 7, 7, 7, -1],\n",
            "           'num_classes': 63,\n",
            "           'regression_range': [(0, 4),\n",
            "                                (4, 8),\n",
            "                                (8, 16),\n",
            "                                (16, 32),\n",
            "                                (32, 64),\n",
            "                                (64, 10000)],\n",
            "           'scale_factor': 2,\n",
            "           'test_cfg': {'duration_thresh': 0.05,\n",
            "                        'ext_score_file': None,\n",
            "                        'iou_threshold': 0.1,\n",
            "                        'max_seg_num': 2000,\n",
            "                        'min_score': 0.001,\n",
            "                        'multiclass_nms': True,\n",
            "                        'nms_method': 'soft',\n",
            "                        'nms_sigma': 0.4,\n",
            "                        'pre_nms_thresh': 0.001,\n",
            "                        'pre_nms_topk': 5000,\n",
            "                        'voting_thresh': 0.75},\n",
            "           'train_cfg': {'center_sample': 'radius',\n",
            "                         'center_sample_radius': 1.5,\n",
            "                         'clip_grad_l2norm': 1.0,\n",
            "                         'cls_prior_prob': 0.01,\n",
            "                         'dropout': 0.0,\n",
            "                         'droppath': 0.1,\n",
            "                         'head_empty_cls': [],\n",
            "                         'init_loss_norm': 250,\n",
            "                         'label_smoothing': 0.0,\n",
            "                         'loss_weight': 1.0},\n",
            "           'use_abs_pe': True,\n",
            "           'use_rel_pe': False},\n",
            " 'model_name': 'LocPointTransformer',\n",
            " 'opt': {'epochs': 30,\n",
            "         'learning_rate': 0.001,\n",
            "         'momentum': 0.9,\n",
            "         'schedule_gamma': 0.1,\n",
            "         'schedule_steps': [],\n",
            "         'schedule_type': 'cosine',\n",
            "         'type': 'AdamW',\n",
            "         'warmup': True,\n",
            "         'warmup_epochs': 5,\n",
            "         'weight_decay': 0.05},\n",
            " 'output_folder': './ckpt/',\n",
            " 'test_cfg': {'duration_thresh': 0.05,\n",
            "              'ext_score_file': None,\n",
            "              'iou_threshold': 0.1,\n",
            "              'max_seg_num': 2000,\n",
            "              'min_score': 0.001,\n",
            "              'multiclass_nms': True,\n",
            "              'nms_method': 'soft',\n",
            "              'nms_sigma': 0.4,\n",
            "              'pre_nms_thresh': 0.001,\n",
            "              'pre_nms_topk': 5000,\n",
            "              'voting_thresh': 0.75},\n",
            " 'train_cfg': {'center_sample': 'radius',\n",
            "               'center_sample_radius': 1.5,\n",
            "               'clip_grad_l2norm': 1.0,\n",
            "               'cls_prior_prob': 0.01,\n",
            "               'dropout': 0.0,\n",
            "               'droppath': 0.1,\n",
            "               'head_empty_cls': [],\n",
            "               'init_loss_norm': 250,\n",
            "               'label_smoothing': 0.0,\n",
            "               'loss_weight': 1.0},\n",
            " 'train_split': ['train'],\n",
            " 'val_split': ['valid']}\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "=> loading checkpoint 'ckpt/perception_video_train_reproduce/epoch_035.pth.tar'\n",
            "Loading from EMA model ...\n",
            "\n",
            "Start testing model LocPointTransformer ...\n",
            "/usr/local/lib/python3.10/dist-packages/torch/utils/data/dataloader.py:560: UserWarning: This DataLoader will create 4 worker processes in total. Our suggested max number of worker in current system is 2, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
            "  warnings.warn(_create_warning_msg(\n",
            "Test: [00010/05768]\tTime 0.31 (0.31)\n",
            "Test: [00020/05768]\tTime 0.08 (0.19)\n",
            "Test: [00030/05768]\tTime 0.08 (0.16)\n",
            "Test: [00040/05768]\tTime 0.08 (0.14)\n",
            "Test: [00050/05768]\tTime 0.08 (0.13)\n",
            "Test: [00060/05768]\tTime 0.08 (0.12)\n",
            "Test: [00070/05768]\tTime 0.08 (0.11)\n",
            "Test: [00080/05768]\tTime 0.08 (0.11)\n",
            "Test: [00090/05768]\tTime 0.08 (0.11)\n",
            "Test: [00100/05768]\tTime 0.08 (0.10)\n",
            "Test: [00110/05768]\tTime 0.08 (0.10)\n",
            "Test: [00120/05768]\tTime 0.11 (0.10)\n",
            "Test: [00130/05768]\tTime 0.11 (0.10)\n",
            "Test: [00140/05768]\tTime 0.10 (0.10)\n",
            "Test: [00150/05768]\tTime 0.08 (0.10)\n",
            "Test: [00160/05768]\tTime 0.08 (0.10)\n",
            "Test: [00170/05768]\tTime 0.08 (0.10)\n",
            "Test: [00180/05768]\tTime 0.08 (0.10)\n",
            "Test: [00190/05768]\tTime 0.08 (0.10)\n",
            "Test: [00200/05768]\tTime 0.08 (0.10)\n",
            "Test: [00210/05768]\tTime 0.08 (0.10)\n",
            "Test: [00220/05768]\tTime 0.08 (0.09)\n",
            "Test: [00230/05768]\tTime 0.08 (0.09)\n",
            "Test: [00240/05768]\tTime 0.08 (0.09)\n",
            "Test: [00250/05768]\tTime 0.08 (0.09)\n",
            "Test: [00260/05768]\tTime 0.09 (0.09)\n",
            "Test: [00270/05768]\tTime 0.11 (0.09)\n",
            "Test: [00280/05768]\tTime 0.12 (0.10)\n",
            "Test: [00290/05768]\tTime 0.09 (0.09)\n",
            "Test: [00300/05768]\tTime 0.08 (0.09)\n",
            "Test: [00310/05768]\tTime 0.09 (0.09)\n",
            "Test: [00320/05768]\tTime 0.08 (0.09)\n",
            "Test: [00330/05768]\tTime 0.08 (0.09)\n",
            "Test: [00340/05768]\tTime 0.08 (0.09)\n",
            "Test: [00350/05768]\tTime 0.08 (0.09)\n",
            "Test: [00360/05768]\tTime 0.08 (0.09)\n",
            "Test: [00370/05768]\tTime 0.08 (0.09)\n",
            "Test: [00380/05768]\tTime 0.08 (0.09)\n",
            "Test: [00390/05768]\tTime 0.08 (0.09)\n",
            "Test: [00400/05768]\tTime 0.08 (0.09)\n",
            "Test: [00410/05768]\tTime 0.11 (0.09)\n",
            "Test: [00420/05768]\tTime 0.11 (0.09)\n",
            "Test: [00430/05768]\tTime 0.11 (0.09)\n",
            "Test: [00440/05768]\tTime 0.08 (0.09)\n",
            "Test: [00450/05768]\tTime 0.08 (0.09)\n",
            "Test: [00460/05768]\tTime 0.09 (0.09)\n",
            "Test: [00470/05768]\tTime 0.08 (0.09)\n",
            "Test: [00480/05768]\tTime 0.08 (0.09)\n",
            "Test: [00490/05768]\tTime 0.10 (0.09)\n",
            "Test: [00500/05768]\tTime 0.08 (0.09)\n",
            "Test: [00510/05768]\tTime 0.08 (0.09)\n",
            "Test: [00520/05768]\tTime 0.08 (0.09)\n",
            "Test: [00530/05768]\tTime 0.08 (0.09)\n",
            "Test: [00540/05768]\tTime 0.08 (0.09)\n",
            "Test: [00550/05768]\tTime 0.10 (0.09)\n",
            "Test: [00560/05768]\tTime 0.11 (0.09)\n",
            "Test: [00570/05768]\tTime 0.11 (0.09)\n",
            "Test: [00580/05768]\tTime 0.08 (0.09)\n",
            "Test: [00590/05768]\tTime 0.08 (0.09)\n",
            "Test: [00600/05768]\tTime 0.08 (0.09)\n",
            "Test: [00610/05768]\tTime 0.08 (0.09)\n",
            "Test: [00620/05768]\tTime 0.08 (0.09)\n",
            "Test: [00630/05768]\tTime 0.08 (0.09)\n",
            "Test: [00640/05768]\tTime 0.08 (0.09)\n",
            "Test: [00650/05768]\tTime 0.08 (0.09)\n",
            "Test: [00660/05768]\tTime 0.08 (0.09)\n",
            "Test: [00670/05768]\tTime 0.08 (0.09)\n",
            "Test: [00680/05768]\tTime 0.08 (0.09)\n",
            "Test: [00690/05768]\tTime 0.08 (0.09)\n",
            "Test: [00700/05768]\tTime 0.09 (0.09)\n",
            "Test: [00710/05768]\tTime 0.11 (0.09)\n",
            "Test: [00720/05768]\tTime 0.11 (0.09)\n",
            "Test: [00730/05768]\tTime 0.09 (0.09)\n",
            "Test: [00740/05768]\tTime 0.08 (0.09)\n",
            "Test: [00750/05768]\tTime 0.08 (0.09)\n",
            "Test: [00760/05768]\tTime 0.08 (0.09)\n",
            "Test: [00770/05768]\tTime 0.08 (0.09)\n",
            "Test: [00780/05768]\tTime 0.08 (0.09)\n",
            "Test: [00790/05768]\tTime 0.08 (0.09)\n",
            "Test: [00800/05768]\tTime 0.08 (0.09)\n",
            "Test: [00810/05768]\tTime 0.08 (0.09)\n",
            "Test: [00820/05768]\tTime 0.08 (0.09)\n",
            "Test: [00830/05768]\tTime 0.08 (0.09)\n",
            "Test: [00840/05768]\tTime 0.08 (0.09)\n",
            "Test: [00850/05768]\tTime 0.08 (0.09)\n",
            "Test: [00860/05768]\tTime 0.11 (0.09)\n",
            "Test: [00870/05768]\tTime 0.11 (0.09)\n",
            "Test: [00880/05768]\tTime 0.10 (0.09)\n",
            "Test: [00890/05768]\tTime 0.08 (0.09)\n",
            "Test: [00900/05768]\tTime 0.08 (0.09)\n",
            "Test: [00910/05768]\tTime 0.08 (0.09)\n",
            "Test: [00920/05768]\tTime 0.08 (0.09)\n",
            "Test: [00930/05768]\tTime 0.08 (0.09)\n",
            "Test: [00940/05768]\tTime 0.07 (0.09)\n",
            "Test: [00950/05768]\tTime 0.08 (0.09)\n",
            "Test: [00960/05768]\tTime 0.08 (0.09)\n",
            "Test: [00970/05768]\tTime 0.08 (0.09)\n",
            "Test: [00980/05768]\tTime 0.08 (0.09)\n",
            "Test: [00990/05768]\tTime 0.08 (0.09)\n",
            "Test: [01000/05768]\tTime 0.08 (0.09)\n",
            "Test: [01010/05768]\tTime 0.09 (0.09)\n",
            "Test: [01020/05768]\tTime 0.11 (0.09)\n",
            "Test: [01030/05768]\tTime 0.10 (0.09)\n",
            "Test: [01040/05768]\tTime 0.08 (0.09)\n",
            "Test: [01050/05768]\tTime 0.08 (0.09)\n",
            "Test: [01060/05768]\tTime 0.08 (0.09)\n",
            "Test: [01070/05768]\tTime 0.08 (0.09)\n",
            "Test: [01080/05768]\tTime 0.08 (0.09)\n",
            "Test: [01090/05768]\tTime 0.08 (0.09)\n",
            "Test: [01100/05768]\tTime 0.08 (0.09)\n",
            "Test: [01110/05768]\tTime 0.08 (0.09)\n",
            "Test: [01120/05768]\tTime 0.08 (0.09)\n",
            "Test: [01130/05768]\tTime 0.08 (0.09)\n",
            "Test: [01140/05768]\tTime 0.08 (0.09)\n",
            "Test: [01150/05768]\tTime 0.08 (0.09)\n",
            "Test: [01160/05768]\tTime 0.08 (0.09)\n",
            "Test: [01170/05768]\tTime 0.11 (0.09)\n",
            "Test: [01180/05768]\tTime 0.11 (0.09)\n",
            "Test: [01190/05768]\tTime 0.09 (0.09)\n",
            "Test: [01200/05768]\tTime 0.08 (0.09)\n",
            "Test: [01210/05768]\tTime 0.08 (0.09)\n",
            "Test: [01220/05768]\tTime 0.07 (0.09)\n",
            "Test: [01230/05768]\tTime 0.08 (0.09)\n",
            "Test: [01240/05768]\tTime 0.08 (0.09)\n",
            "Test: [01250/05768]\tTime 0.08 (0.09)\n",
            "Test: [01260/05768]\tTime 0.08 (0.09)\n",
            "Test: [01270/05768]\tTime 0.07 (0.09)\n",
            "Test: [01280/05768]\tTime 0.07 (0.09)\n",
            "Test: [01290/05768]\tTime 0.08 (0.09)\n",
            "Test: [01300/05768]\tTime 0.08 (0.09)\n",
            "Test: [01310/05768]\tTime 0.08 (0.09)\n",
            "Test: [01320/05768]\tTime 0.09 (0.09)\n",
            "Test: [01330/05768]\tTime 0.10 (0.09)\n",
            "Test: [01340/05768]\tTime 0.11 (0.09)\n",
            "Test: [01350/05768]\tTime 0.09 (0.09)\n",
            "Test: [01360/05768]\tTime 0.08 (0.09)\n",
            "Test: [01370/05768]\tTime 0.08 (0.09)\n",
            "Test: [01380/05768]\tTime 0.08 (0.09)\n",
            "Test: [01390/05768]\tTime 0.08 (0.09)\n",
            "Test: [01400/05768]\tTime 0.08 (0.09)\n",
            "Test: [01410/05768]\tTime 0.08 (0.09)\n",
            "Test: [01420/05768]\tTime 0.08 (0.09)\n",
            "Test: [01430/05768]\tTime 0.08 (0.09)\n",
            "Test: [01440/05768]\tTime 0.08 (0.09)\n",
            "Test: [01450/05768]\tTime 0.08 (0.09)\n",
            "Test: [01460/05768]\tTime 0.08 (0.09)\n",
            "Test: [01470/05768]\tTime 0.08 (0.09)\n",
            "Test: [01480/05768]\tTime 0.10 (0.09)\n",
            "Test: [01490/05768]\tTime 0.11 (0.09)\n",
            "Test: [01500/05768]\tTime 0.11 (0.09)\n",
            "Test: [01510/05768]\tTime 0.08 (0.09)\n",
            "Test: [01520/05768]\tTime 0.08 (0.09)\n",
            "Test: [01530/05768]\tTime 0.08 (0.09)\n",
            "Test: [01540/05768]\tTime 0.08 (0.09)\n",
            "Test: [01550/05768]\tTime 0.08 (0.09)\n",
            "Test: [01560/05768]\tTime 0.08 (0.09)\n",
            "Test: [01570/05768]\tTime 0.08 (0.09)\n",
            "Test: [01580/05768]\tTime 0.08 (0.09)\n",
            "Test: [01590/05768]\tTime 0.08 (0.09)\n",
            "Test: [01600/05768]\tTime 0.08 (0.09)\n",
            "Test: [01610/05768]\tTime 0.08 (0.09)\n",
            "Test: [01620/05768]\tTime 0.08 (0.09)\n",
            "Test: [01630/05768]\tTime 0.09 (0.09)\n",
            "Test: [01640/05768]\tTime 0.11 (0.09)\n",
            "Test: [01650/05768]\tTime 0.11 (0.09)\n",
            "Test: [01660/05768]\tTime 0.08 (0.09)\n",
            "Test: [01670/05768]\tTime 0.08 (0.09)\n",
            "Test: [01680/05768]\tTime 0.08 (0.09)\n",
            "Test: [01690/05768]\tTime 0.07 (0.09)\n",
            "Test: [01700/05768]\tTime 0.07 (0.09)\n",
            "Test: [01710/05768]\tTime 0.08 (0.09)\n",
            "Test: [01720/05768]\tTime 0.08 (0.09)\n",
            "Test: [01730/05768]\tTime 0.08 (0.09)\n",
            "Test: [01740/05768]\tTime 0.08 (0.09)\n",
            "Test: [01750/05768]\tTime 0.08 (0.09)\n",
            "Test: [01760/05768]\tTime 0.08 (0.09)\n",
            "Test: [01770/05768]\tTime 0.08 (0.09)\n",
            "Test: [01780/05768]\tTime 0.09 (0.09)\n",
            "Test: [01790/05768]\tTime 0.11 (0.09)\n",
            "Test: [01800/05768]\tTime 0.11 (0.09)\n",
            "Test: [01810/05768]\tTime 0.09 (0.09)\n",
            "Test: [01820/05768]\tTime 0.08 (0.09)\n",
            "Test: [01830/05768]\tTime 0.08 (0.09)\n",
            "Test: [01840/05768]\tTime 0.08 (0.09)\n",
            "Test: [01850/05768]\tTime 0.08 (0.09)\n",
            "Test: [01860/05768]\tTime 0.08 (0.09)\n",
            "Test: [01870/05768]\tTime 0.08 (0.09)\n",
            "Test: [01880/05768]\tTime 0.08 (0.09)\n",
            "Test: [01890/05768]\tTime 0.08 (0.09)\n",
            "Test: [01900/05768]\tTime 0.08 (0.09)\n",
            "Test: [01910/05768]\tTime 0.08 (0.09)\n",
            "Test: [01920/05768]\tTime 0.08 (0.09)\n",
            "Test: [01930/05768]\tTime 0.10 (0.09)\n",
            "Test: [01940/05768]\tTime 0.12 (0.09)\n",
            "Test: [01950/05768]\tTime 0.11 (0.09)\n",
            "Test: [01960/05768]\tTime 0.08 (0.09)\n",
            "Test: [01970/05768]\tTime 0.08 (0.09)\n",
            "Test: [01980/05768]\tTime 0.08 (0.09)\n",
            "Test: [01990/05768]\tTime 0.08 (0.09)\n",
            "Test: [02000/05768]\tTime 0.08 (0.09)\n",
            "Test: [02010/05768]\tTime 0.08 (0.09)\n",
            "Test: [02020/05768]\tTime 0.08 (0.09)\n",
            "Test: [02030/05768]\tTime 0.08 (0.09)\n",
            "Test: [02040/05768]\tTime 0.08 (0.09)\n",
            "Test: [02050/05768]\tTime 0.08 (0.09)\n",
            "Test: [02060/05768]\tTime 0.08 (0.09)\n",
            "Test: [02070/05768]\tTime 0.08 (0.09)\n",
            "Test: [02080/05768]\tTime 0.10 (0.09)\n",
            "Test: [02090/05768]\tTime 0.11 (0.09)\n",
            "Test: [02100/05768]\tTime 0.11 (0.09)\n",
            "Test: [02110/05768]\tTime 0.08 (0.09)\n",
            "Test: [02120/05768]\tTime 0.08 (0.09)\n",
            "Test: [02130/05768]\tTime 0.08 (0.09)\n",
            "Test: [02140/05768]\tTime 0.07 (0.09)\n",
            "Test: [02150/05768]\tTime 0.08 (0.09)\n",
            "Test: [02160/05768]\tTime 0.08 (0.09)\n",
            "Test: [02170/05768]\tTime 0.08 (0.09)\n",
            "Test: [02180/05768]\tTime 0.08 (0.09)\n",
            "Test: [02190/05768]\tTime 0.08 (0.09)\n",
            "Test: [02200/05768]\tTime 0.07 (0.09)\n",
            "Test: [02210/05768]\tTime 0.08 (0.09)\n",
            "Test: [02220/05768]\tTime 0.08 (0.09)\n",
            "Test: [02230/05768]\tTime 0.08 (0.09)\n",
            "Test: [02240/05768]\tTime 0.11 (0.09)\n",
            "Test: [02250/05768]\tTime 0.11 (0.09)\n",
            "Test: [02260/05768]\tTime 0.10 (0.09)\n",
            "Test: [02270/05768]\tTime 0.07 (0.09)\n",
            "Test: [02280/05768]\tTime 0.07 (0.09)\n",
            "Test: [02290/05768]\tTime 0.07 (0.09)\n",
            "Test: [02300/05768]\tTime 0.07 (0.09)\n",
            "Test: [02310/05768]\tTime 0.07 (0.09)\n",
            "Test: [02320/05768]\tTime 0.07 (0.09)\n",
            "Test: [02330/05768]\tTime 0.07 (0.09)\n",
            "Test: [02340/05768]\tTime 0.07 (0.09)\n",
            "Test: [02350/05768]\tTime 0.07 (0.09)\n",
            "Test: [02360/05768]\tTime 0.07 (0.09)\n",
            "Test: [02370/05768]\tTime 0.07 (0.09)\n",
            "Test: [02380/05768]\tTime 0.07 (0.09)\n",
            "Test: [02390/05768]\tTime 0.07 (0.08)\n",
            "Test: [02400/05768]\tTime 0.10 (0.09)\n",
            "Test: [02410/05768]\tTime 0.11 (0.09)\n",
            "Test: [02420/05768]\tTime 0.11 (0.09)\n",
            "Test: [02430/05768]\tTime 0.08 (0.09)\n",
            "Test: [02440/05768]\tTime 0.08 (0.09)\n",
            "Test: [02450/05768]\tTime 0.08 (0.09)\n",
            "Test: [02460/05768]\tTime 0.08 (0.09)\n",
            "Test: [02470/05768]\tTime 0.08 (0.09)\n",
            "Test: [02480/05768]\tTime 0.08 (0.09)\n",
            "Test: [02490/05768]\tTime 0.08 (0.09)\n",
            "Test: [02500/05768]\tTime 0.08 (0.09)\n",
            "Test: [02510/05768]\tTime 0.08 (0.09)\n",
            "Test: [02520/05768]\tTime 0.08 (0.09)\n",
            "Test: [02530/05768]\tTime 0.08 (0.08)\n",
            "Test: [02540/05768]\tTime 0.08 (0.08)\n",
            "Test: [02550/05768]\tTime 0.09 (0.08)\n",
            "Test: [02560/05768]\tTime 0.11 (0.09)\n",
            "Test: [02570/05768]\tTime 0.11 (0.09)\n",
            "Test: [02580/05768]\tTime 0.09 (0.09)\n",
            "Test: [02590/05768]\tTime 0.08 (0.09)\n",
            "Test: [02600/05768]\tTime 0.08 (0.09)\n",
            "Test: [02610/05768]\tTime 0.08 (0.09)\n",
            "Test: [02620/05768]\tTime 0.08 (0.09)\n",
            "Test: [02630/05768]\tTime 0.08 (0.09)\n",
            "Test: [02640/05768]\tTime 0.08 (0.08)\n",
            "Test: [02650/05768]\tTime 0.08 (0.08)\n",
            "Test: [02660/05768]\tTime 0.08 (0.08)\n",
            "Test: [02670/05768]\tTime 0.08 (0.08)\n",
            "Test: [02680/05768]\tTime 0.08 (0.08)\n",
            "Test: [02690/05768]\tTime 0.08 (0.08)\n",
            "Test: [02700/05768]\tTime 0.08 (0.08)\n",
            "Test: [02710/05768]\tTime 0.10 (0.08)\n",
            "Test: [02720/05768]\tTime 0.11 (0.08)\n",
            "Test: [02730/05768]\tTime 0.11 (0.09)\n",
            "Test: [02740/05768]\tTime 0.08 (0.09)\n",
            "Test: [02750/05768]\tTime 0.08 (0.09)\n",
            "Test: [02760/05768]\tTime 0.08 (0.08)\n",
            "Test: [02770/05768]\tTime 0.08 (0.08)\n",
            "Test: [02780/05768]\tTime 0.08 (0.08)\n",
            "Test: [02790/05768]\tTime 0.08 (0.08)\n",
            "Test: [02800/05768]\tTime 0.08 (0.08)\n",
            "Test: [02810/05768]\tTime 0.08 (0.08)\n",
            "Test: [02820/05768]\tTime 0.08 (0.08)\n",
            "Test: [02830/05768]\tTime 0.08 (0.08)\n",
            "Test: [02840/05768]\tTime 0.08 (0.08)\n",
            "Test: [02850/05768]\tTime 0.08 (0.08)\n",
            "Test: [02860/05768]\tTime 0.10 (0.08)\n",
            "Test: [02870/05768]\tTime 0.11 (0.08)\n",
            "Test: [02880/05768]\tTime 0.11 (0.09)\n",
            "Test: [02890/05768]\tTime 0.08 (0.09)\n",
            "Test: [02900/05768]\tTime 0.08 (0.08)\n",
            "Test: [02910/05768]\tTime 0.08 (0.08)\n",
            "Test: [02920/05768]\tTime 0.08 (0.08)\n",
            "Test: [02930/05768]\tTime 0.08 (0.08)\n",
            "Test: [02940/05768]\tTime 0.08 (0.08)\n",
            "Test: [02950/05768]\tTime 0.08 (0.08)\n",
            "Test: [02960/05768]\tTime 0.08 (0.08)\n",
            "Test: [02970/05768]\tTime 0.07 (0.08)\n",
            "Test: [02980/05768]\tTime 0.08 (0.08)\n",
            "Test: [02990/05768]\tTime 0.07 (0.08)\n",
            "Test: [03000/05768]\tTime 0.08 (0.08)\n",
            "Test: [03010/05768]\tTime 0.08 (0.08)\n",
            "Test: [03020/05768]\tTime 0.11 (0.08)\n",
            "Test: [03030/05768]\tTime 0.11 (0.08)\n",
            "Test: [03040/05768]\tTime 0.10 (0.08)\n",
            "Test: [03050/05768]\tTime 0.08 (0.08)\n",
            "Test: [03060/05768]\tTime 0.08 (0.08)\n",
            "Test: [03070/05768]\tTime 0.08 (0.08)\n",
            "Test: [03080/05768]\tTime 0.08 (0.08)\n",
            "Test: [03090/05768]\tTime 0.08 (0.08)\n",
            "Test: [03100/05768]\tTime 0.08 (0.08)\n",
            "Test: [03110/05768]\tTime 0.08 (0.08)\n",
            "Test: [03120/05768]\tTime 0.08 (0.08)\n",
            "Test: [03130/05768]\tTime 0.08 (0.08)\n",
            "Test: [03140/05768]\tTime 0.08 (0.08)\n",
            "Test: [03150/05768]\tTime 0.08 (0.08)\n",
            "Test: [03160/05768]\tTime 0.08 (0.08)\n",
            "Test: [03170/05768]\tTime 0.09 (0.08)\n",
            "Test: [03180/05768]\tTime 0.11 (0.08)\n",
            "Test: [03190/05768]\tTime 0.11 (0.08)\n",
            "Test: [03200/05768]\tTime 0.08 (0.08)\n",
            "Test: [03210/05768]\tTime 0.08 (0.08)\n",
            "Test: [03220/05768]\tTime 0.08 (0.08)\n",
            "Test: [03230/05768]\tTime 0.08 (0.08)\n",
            "Test: [03240/05768]\tTime 0.08 (0.08)\n",
            "Test: [03250/05768]\tTime 0.08 (0.08)\n",
            "Test: [03260/05768]\tTime 0.08 (0.08)\n",
            "Test: [03270/05768]\tTime 0.08 (0.08)\n",
            "Test: [03280/05768]\tTime 0.08 (0.08)\n",
            "Test: [03290/05768]\tTime 0.08 (0.08)\n",
            "Test: [03300/05768]\tTime 0.08 (0.08)\n",
            "Test: [03310/05768]\tTime 0.08 (0.08)\n",
            "Test: [03320/05768]\tTime 0.09 (0.08)\n",
            "Test: [03330/05768]\tTime 0.11 (0.08)\n",
            "Test: [03340/05768]\tTime 0.11 (0.08)\n",
            "Test: [03350/05768]\tTime 0.09 (0.08)\n",
            "Test: [03360/05768]\tTime 0.08 (0.08)\n",
            "Test: [03370/05768]\tTime 0.08 (0.08)\n",
            "Test: [03380/05768]\tTime 0.08 (0.08)\n",
            "Test: [03390/05768]\tTime 0.08 (0.08)\n",
            "Test: [03400/05768]\tTime 0.08 (0.08)\n",
            "Test: [03410/05768]\tTime 0.08 (0.08)\n",
            "Test: [03420/05768]\tTime 0.08 (0.08)\n",
            "Test: [03430/05768]\tTime 0.08 (0.08)\n",
            "Test: [03440/05768]\tTime 0.08 (0.08)\n",
            "Test: [03450/05768]\tTime 0.08 (0.08)\n",
            "Test: [03460/05768]\tTime 0.08 (0.08)\n",
            "Test: [03470/05768]\tTime 0.08 (0.08)\n",
            "Test: [03480/05768]\tTime 0.11 (0.08)\n",
            "Test: [03490/05768]\tTime 0.11 (0.08)\n",
            "Test: [03500/05768]\tTime 0.09 (0.08)\n",
            "Test: [03510/05768]\tTime 0.08 (0.08)\n",
            "Test: [03520/05768]\tTime 0.08 (0.08)\n",
            "Test: [03530/05768]\tTime 0.08 (0.08)\n",
            "Test: [03540/05768]\tTime 0.08 (0.08)\n",
            "Test: [03550/05768]\tTime 0.08 (0.08)\n",
            "Test: [03560/05768]\tTime 0.08 (0.08)\n",
            "Test: [03570/05768]\tTime 0.08 (0.08)\n",
            "Test: [03580/05768]\tTime 0.08 (0.08)\n",
            "Test: [03590/05768]\tTime 0.08 (0.08)\n",
            "Test: [03600/05768]\tTime 0.08 (0.08)\n",
            "Test: [03610/05768]\tTime 0.08 (0.08)\n",
            "Test: [03620/05768]\tTime 0.09 (0.08)\n",
            "Test: [03630/05768]\tTime 0.11 (0.08)\n",
            "Test: [03640/05768]\tTime 0.11 (0.08)\n",
            "Test: [03650/05768]\tTime 0.09 (0.08)\n",
            "Test: [03660/05768]\tTime 0.08 (0.08)\n",
            "Test: [03670/05768]\tTime 0.08 (0.08)\n",
            "Test: [03680/05768]\tTime 0.08 (0.08)\n",
            "Test: [03690/05768]\tTime 0.08 (0.08)\n",
            "Test: [03700/05768]\tTime 0.08 (0.08)\n",
            "Test: [03710/05768]\tTime 0.08 (0.08)\n",
            "Test: [03720/05768]\tTime 0.08 (0.08)\n",
            "Test: [03730/05768]\tTime 0.08 (0.08)\n",
            "Test: [03740/05768]\tTime 0.08 (0.08)\n",
            "Test: [03750/05768]\tTime 0.08 (0.08)\n",
            "Test: [03760/05768]\tTime 0.08 (0.08)\n",
            "Test: [03770/05768]\tTime 0.08 (0.08)\n",
            "Test: [03780/05768]\tTime 0.10 (0.08)\n",
            "Test: [03790/05768]\tTime 0.11 (0.08)\n",
            "Test: [03800/05768]\tTime 0.11 (0.08)\n",
            "Test: [03810/05768]\tTime 0.08 (0.08)\n",
            "Test: [03820/05768]\tTime 0.08 (0.08)\n",
            "Test: [03830/05768]\tTime 0.08 (0.08)\n",
            "Test: [03840/05768]\tTime 0.08 (0.08)\n",
            "Test: [03850/05768]\tTime 0.08 (0.08)\n",
            "Test: [03860/05768]\tTime 0.08 (0.08)\n",
            "Test: [03870/05768]\tTime 0.08 (0.08)\n",
            "Test: [03880/05768]\tTime 0.08 (0.08)\n",
            "Test: [03890/05768]\tTime 0.08 (0.08)\n",
            "Test: [03900/05768]\tTime 0.08 (0.08)\n",
            "Test: [03910/05768]\tTime 0.08 (0.08)\n",
            "Test: [03920/05768]\tTime 0.08 (0.08)\n",
            "Test: [03930/05768]\tTime 0.09 (0.08)\n",
            "Test: [03940/05768]\tTime 0.11 (0.08)\n",
            "Test: [03950/05768]\tTime 0.11 (0.08)\n",
            "Test: [03960/05768]\tTime 0.08 (0.08)\n",
            "Test: [03970/05768]\tTime 0.08 (0.08)\n",
            "Test: [03980/05768]\tTime 0.08 (0.08)\n",
            "Test: [03990/05768]\tTime 0.08 (0.08)\n",
            "Test: [04000/05768]\tTime 0.08 (0.08)\n",
            "Test: [04010/05768]\tTime 0.08 (0.08)\n",
            "Test: [04020/05768]\tTime 0.08 (0.08)\n",
            "Test: [04030/05768]\tTime 0.08 (0.08)\n",
            "Test: [04040/05768]\tTime 0.08 (0.08)\n",
            "Test: [04050/05768]\tTime 0.08 (0.08)\n",
            "Test: [04060/05768]\tTime 0.08 (0.08)\n",
            "Test: [04070/05768]\tTime 0.08 (0.08)\n",
            "Test: [04080/05768]\tTime 0.08 (0.08)\n",
            "Test: [04090/05768]\tTime 0.10 (0.08)\n",
            "Test: [04100/05768]\tTime 0.11 (0.08)\n",
            "Test: [04110/05768]\tTime 0.10 (0.08)\n",
            "Test: [04120/05768]\tTime 0.08 (0.08)\n",
            "Test: [04130/05768]\tTime 0.08 (0.08)\n",
            "Test: [04140/05768]\tTime 0.08 (0.08)\n",
            "Test: [04150/05768]\tTime 0.08 (0.08)\n",
            "Test: [04160/05768]\tTime 0.08 (0.08)\n",
            "Test: [04170/05768]\tTime 0.08 (0.08)\n",
            "Test: [04180/05768]\tTime 0.08 (0.08)\n",
            "Test: [04190/05768]\tTime 0.08 (0.08)\n",
            "Test: [04200/05768]\tTime 0.08 (0.08)\n",
            "Test: [04210/05768]\tTime 0.08 (0.08)\n",
            "Test: [04220/05768]\tTime 0.08 (0.08)\n",
            "Test: [04230/05768]\tTime 0.08 (0.08)\n",
            "Test: [04240/05768]\tTime 0.09 (0.08)\n",
            "Test: [04250/05768]\tTime 0.10 (0.08)\n",
            "Test: [04260/05768]\tTime 0.11 (0.08)\n",
            "Test: [04270/05768]\tTime 0.08 (0.08)\n",
            "Test: [04280/05768]\tTime 0.08 (0.08)\n",
            "Test: [04290/05768]\tTime 0.08 (0.08)\n",
            "Test: [04300/05768]\tTime 0.08 (0.08)\n",
            "Test: [04310/05768]\tTime 0.08 (0.08)\n",
            "Test: [04320/05768]\tTime 0.08 (0.08)\n",
            "Test: [04330/05768]\tTime 0.08 (0.08)\n",
            "Test: [04340/05768]\tTime 0.08 (0.08)\n",
            "Test: [04350/05768]\tTime 0.08 (0.08)\n",
            "Test: [04360/05768]\tTime 0.09 (0.08)\n",
            "Test: [04370/05768]\tTime 0.08 (0.08)\n",
            "Test: [04380/05768]\tTime 0.08 (0.08)\n",
            "Test: [04390/05768]\tTime 0.10 (0.08)\n",
            "Test: [04400/05768]\tTime 0.11 (0.08)\n",
            "Test: [04410/05768]\tTime 0.11 (0.08)\n",
            "Test: [04420/05768]\tTime 0.08 (0.08)\n",
            "Test: [04430/05768]\tTime 0.08 (0.08)\n",
            "Test: [04440/05768]\tTime 0.08 (0.08)\n",
            "Test: [04450/05768]\tTime 0.08 (0.08)\n",
            "Test: [04460/05768]\tTime 0.08 (0.08)\n",
            "Test: [04470/05768]\tTime 0.08 (0.08)\n",
            "Test: [04480/05768]\tTime 0.08 (0.08)\n",
            "Test: [04490/05768]\tTime 0.08 (0.08)\n",
            "Test: [04500/05768]\tTime 0.08 (0.08)\n",
            "Test: [04510/05768]\tTime 0.08 (0.08)\n",
            "Test: [04520/05768]\tTime 0.08 (0.08)\n",
            "Test: [04530/05768]\tTime 0.08 (0.08)\n",
            "Test: [04540/05768]\tTime 0.10 (0.08)\n",
            "Test: [04550/05768]\tTime 0.11 (0.08)\n",
            "Test: [04560/05768]\tTime 0.11 (0.08)\n",
            "Test: [04570/05768]\tTime 0.08 (0.08)\n",
            "Test: [04580/05768]\tTime 0.08 (0.08)\n",
            "Test: [04590/05768]\tTime 0.08 (0.08)\n",
            "Test: [04600/05768]\tTime 0.08 (0.08)\n",
            "Test: [04610/05768]\tTime 0.08 (0.08)\n",
            "Test: [04620/05768]\tTime 0.08 (0.08)\n",
            "Test: [04630/05768]\tTime 0.08 (0.08)\n",
            "Test: [04640/05768]\tTime 0.08 (0.08)\n",
            "Test: [04650/05768]\tTime 0.08 (0.08)\n",
            "Test: [04660/05768]\tTime 0.08 (0.08)\n",
            "Test: [04670/05768]\tTime 0.08 (0.08)\n",
            "Test: [04680/05768]\tTime 0.08 (0.08)\n",
            "Test: [04690/05768]\tTime 0.10 (0.08)\n",
            "Test: [04700/05768]\tTime 0.11 (0.08)\n",
            "Test: [04710/05768]\tTime 0.11 (0.08)\n",
            "Test: [04720/05768]\tTime 0.08 (0.08)\n",
            "Test: [04730/05768]\tTime 0.08 (0.08)\n",
            "Test: [04740/05768]\tTime 0.08 (0.08)\n",
            "Test: [04750/05768]\tTime 0.08 (0.08)\n",
            "Test: [04760/05768]\tTime 0.08 (0.08)\n",
            "Test: [04770/05768]\tTime 0.08 (0.08)\n",
            "Test: [04780/05768]\tTime 0.08 (0.08)\n",
            "Test: [04790/05768]\tTime 0.08 (0.08)\n",
            "Test: [04800/05768]\tTime 0.08 (0.08)\n",
            "Test: [04810/05768]\tTime 0.08 (0.08)\n",
            "Test: [04820/05768]\tTime 0.08 (0.08)\n",
            "Test: [04830/05768]\tTime 0.09 (0.08)\n",
            "Test: [04840/05768]\tTime 0.12 (0.08)\n",
            "Test: [04850/05768]\tTime 0.12 (0.08)\n",
            "Test: [04860/05768]\tTime 0.10 (0.08)\n",
            "Test: [04870/05768]\tTime 0.07 (0.08)\n",
            "Test: [04880/05768]\tTime 0.08 (0.08)\n",
            "Test: [04890/05768]\tTime 0.07 (0.08)\n",
            "Test: [04900/05768]\tTime 0.07 (0.08)\n",
            "Test: [04910/05768]\tTime 0.07 (0.08)\n",
            "Test: [04920/05768]\tTime 0.07 (0.08)\n",
            "Test: [04930/05768]\tTime 0.07 (0.08)\n",
            "Test: [04940/05768]\tTime 0.07 (0.08)\n",
            "Test: [04950/05768]\tTime 0.07 (0.08)\n",
            "Test: [04960/05768]\tTime 0.07 (0.08)\n",
            "Test: [04970/05768]\tTime 0.08 (0.08)\n",
            "Test: [04980/05768]\tTime 0.09 (0.08)\n",
            "Test: [04990/05768]\tTime 0.09 (0.08)\n",
            "Test: [05000/05768]\tTime 0.12 (0.08)\n",
            "Test: [05010/05768]\tTime 0.12 (0.08)\n",
            "Test: [05020/05768]\tTime 0.10 (0.08)\n",
            "Test: [05030/05768]\tTime 0.08 (0.08)\n",
            "Test: [05040/05768]\tTime 0.08 (0.08)\n",
            "Test: [05050/05768]\tTime 0.08 (0.08)\n",
            "Test: [05060/05768]\tTime 0.08 (0.08)\n",
            "Test: [05070/05768]\tTime 0.08 (0.08)\n",
            "Test: [05080/05768]\tTime 0.08 (0.08)\n",
            "Test: [05090/05768]\tTime 0.08 (0.08)\n",
            "Test: [05100/05768]\tTime 0.08 (0.08)\n",
            "Test: [05110/05768]\tTime 0.08 (0.08)\n",
            "Test: [05120/05768]\tTime 0.08 (0.08)\n",
            "Test: [05130/05768]\tTime 0.08 (0.08)\n",
            "Test: [05140/05768]\tTime 0.10 (0.08)\n",
            "Test: [05150/05768]\tTime 0.11 (0.08)\n",
            "Test: [05160/05768]\tTime 0.11 (0.08)\n",
            "Test: [05170/05768]\tTime 0.09 (0.08)\n",
            "Test: [05180/05768]\tTime 0.08 (0.08)\n",
            "Test: [05190/05768]\tTime 0.08 (0.08)\n",
            "Test: [05200/05768]\tTime 0.08 (0.08)\n",
            "Test: [05210/05768]\tTime 0.08 (0.08)\n",
            "Test: [05220/05768]\tTime 0.08 (0.08)\n",
            "Test: [05230/05768]\tTime 0.08 (0.08)\n",
            "Test: [05240/05768]\tTime 0.08 (0.08)\n",
            "Test: [05250/05768]\tTime 0.08 (0.08)\n",
            "Test: [05260/05768]\tTime 0.08 (0.08)\n",
            "Test: [05270/05768]\tTime 0.08 (0.08)\n",
            "Test: [05280/05768]\tTime 0.08 (0.08)\n",
            "Test: [05290/05768]\tTime 0.10 (0.08)\n",
            "Test: [05300/05768]\tTime 0.12 (0.08)\n",
            "Test: [05310/05768]\tTime 0.12 (0.08)\n",
            "Test: [05320/05768]\tTime 0.08 (0.08)\n",
            "Test: [05330/05768]\tTime 0.08 (0.08)\n",
            "Test: [05340/05768]\tTime 0.08 (0.08)\n",
            "Test: [05350/05768]\tTime 0.08 (0.08)\n",
            "Test: [05360/05768]\tTime 0.08 (0.08)\n",
            "Test: [05370/05768]\tTime 0.08 (0.08)\n",
            "Test: [05380/05768]\tTime 0.08 (0.08)\n",
            "Test: [05390/05768]\tTime 0.09 (0.08)\n",
            "Test: [05400/05768]\tTime 0.08 (0.08)\n",
            "Test: [05410/05768]\tTime 0.08 (0.08)\n",
            "Test: [05420/05768]\tTime 0.08 (0.08)\n",
            "Test: [05430/05768]\tTime 0.08 (0.08)\n",
            "Test: [05440/05768]\tTime 0.11 (0.08)\n",
            "Test: [05450/05768]\tTime 0.12 (0.09)\n",
            "Test: [05460/05768]\tTime 0.11 (0.09)\n",
            "Test: [05470/05768]\tTime 0.08 (0.09)\n",
            "Test: [05480/05768]\tTime 0.08 (0.09)\n",
            "Test: [05490/05768]\tTime 0.08 (0.09)\n",
            "Test: [05500/05768]\tTime 0.08 (0.09)\n",
            "Test: [05510/05768]\tTime 0.08 (0.09)\n",
            "Test: [05520/05768]\tTime 0.08 (0.09)\n",
            "Test: [05530/05768]\tTime 0.08 (0.09)\n",
            "Test: [05540/05768]\tTime 0.08 (0.09)\n",
            "Test: [05550/05768]\tTime 0.08 (0.08)\n",
            "Test: [05560/05768]\tTime 0.08 (0.08)\n",
            "Test: [05570/05768]\tTime 0.08 (0.08)\n",
            "Test: [05580/05768]\tTime 0.09 (0.08)\n",
            "Test: [05590/05768]\tTime 0.11 (0.09)\n",
            "Test: [05600/05768]\tTime 0.11 (0.09)\n",
            "Test: [05610/05768]\tTime 0.09 (0.09)\n",
            "Test: [05620/05768]\tTime 0.08 (0.09)\n",
            "Test: [05630/05768]\tTime 0.08 (0.09)\n",
            "Test: [05640/05768]\tTime 0.08 (0.09)\n",
            "Test: [05650/05768]\tTime 0.09 (0.09)\n",
            "Test: [05660/05768]\tTime 0.08 (0.09)\n",
            "Test: [05670/05768]\tTime 0.09 (0.09)\n",
            "Test: [05680/05768]\tTime 0.09 (0.09)\n",
            "Test: [05690/05768]\tTime 0.07 (0.09)\n",
            "Test: [05700/05768]\tTime 0.08 (0.09)\n",
            "Test: [05710/05768]\tTime 0.08 (0.09)\n",
            "Test: [05720/05768]\tTime 0.08 (0.09)\n",
            "Test: [05730/05768]\tTime 0.10 (0.09)\n",
            "Test: [05740/05768]\tTime 0.12 (0.09)\n",
            "Test: [05750/05768]\tTime 0.11 (0.09)\n",
            "Test: [05760/05768]\tTime 0.08 (0.09)\n",
            "Warning: No predictions of label '34' were provdied.\n",
            "Warning: No predictions of label '36' were provdied.\n",
            "Warning: No predictions of label '39' were provdied.\n",
            "Warning: No predictions of label '34' were provdied.\n",
            "Warning: No predictions of label '36' were provdied.\n",
            "Warning: No predictions of label '39' were provdied.\n",
            "[RESULTS] Action detection results on action_localisation_valid.\n",
            "\n",
            "|tIoU = 0.10: mAP = 17.21 (%) Recall@1x = 57.48 (%) Recall@5x = 82.97 (%) \n",
            "|tIoU = 0.20: mAP = 16.22 (%) Recall@1x = 51.68 (%) Recall@5x = 79.15 (%) \n",
            "|tIoU = 0.30: mAP = 14.76 (%) Recall@1x = 45.91 (%) Recall@5x = 74.13 (%) \n",
            "|tIoU = 0.40: mAP = 12.99 (%) Recall@1x = 40.36 (%) Recall@5x = 67.82 (%) \n",
            "|tIoU = 0.50: mAP = 10.79 (%) Recall@1x = 34.53 (%) Recall@5x = 59.60 (%) \n",
            "Average mAP: 14.39 (%)\n",
            "All done! Total time: 3632.68 sec\n"
          ]
        }
      ]
    }
  ]
}